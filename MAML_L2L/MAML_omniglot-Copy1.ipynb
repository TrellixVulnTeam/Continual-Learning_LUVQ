{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Lambda(nn.Module):\n",
    "\n",
    "#     def __init__(self, fn):\n",
    "#         super(Lambda, self).__init__()\n",
    "#         self.fn = fn\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omniglot\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "mini-imagenet\n",
      "tiered-imagenet\n",
      "fc100\n",
      "cifarfs\n"
     ]
    }
   ],
   "source": [
    "import learn2learn as l2l\n",
    "for name in l2l.vision.benchmarks.list_tasksets():\n",
    "    print(name)\n",
    "    if(\"tiered-imagenet\" == name):\n",
    "        continue\n",
    "    tasksets = l2l.vision.benchmarks.get_tasksets(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = [\n",
    "    \"omniglot\",]\n",
    "#             \"mini-imagenet\", \n",
    "#             \"fc100\", \"cifarfs\", \"tiered-imagenet\"]\n",
    "# WaysAndShots = [\"omniglot\", \"mini-imagenet\", \"fc100\", \"cifarfs\", \"tiered-imagenet\"]\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Demonstrates how to:\n",
    "    * use the MAML wrapper for fast-adaptation,\n",
    "    * use the benchmark interface to load Omniglot, and\n",
    "    * sample tasks and split them in adaptation and evaluation sets.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### omniglot ###############\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "\n",
      "Iteration 0\n",
      "Meta Train Error 1.5664074830710888\n",
      "Meta Train Accuracy 0.33750000735744834\n",
      "Meta Valid Error 1.5736553594470024\n",
      "Meta Valid Accuracy 0.2875000066123903\n",
      "\n",
      "\n",
      "Iteration 32\n",
      "Meta Train Error 1.0495170950889587\n",
      "Meta Train Accuracy 0.5812500109896064\n",
      "Meta Valid Error 1.0092181013897061\n",
      "Meta Valid Accuracy 0.6187500106170774\n",
      "\n",
      "\n",
      "Iteration 64\n",
      "Meta Train Error 0.8851228686980903\n",
      "Meta Train Accuracy 0.7062500067986548\n",
      "Meta Valid Error 0.8873503152281046\n",
      "Meta Valid Accuracy 0.6437500123865902\n",
      "\n",
      "\n",
      "Iteration 96\n",
      "Meta Train Error 0.8296206104569137\n",
      "Meta Train Accuracy 0.6687500108964741\n",
      "Meta Valid Error 0.6032072734087706\n",
      "Meta Valid Accuracy 0.8000000072643161\n",
      "\n",
      "\n",
      "Iteration 128\n",
      "Meta Train Error 0.7989718918688595\n",
      "Meta Train Accuracy 0.706250011920929\n",
      "Meta Valid Error 0.8273054286837578\n",
      "Meta Valid Accuracy 0.6937500112690032\n",
      "\n",
      "\n",
      "Iteration 160\n",
      "Meta Train Error 0.7038287431932986\n",
      "Meta Train Accuracy 0.7062500109896064\n",
      "Meta Valid Error 0.9559635068289936\n",
      "Meta Valid Accuracy 0.631250012665987\n",
      "\n",
      "\n",
      "Iteration 192\n",
      "Meta Train Error 0.7997465545777231\n",
      "Meta Train Accuracy 0.7000000141561031\n",
      "Meta Valid Error 0.8806346287019551\n",
      "Meta Valid Accuracy 0.6500000115483999\n",
      "\n",
      "\n",
      "Iteration 224\n",
      "Meta Train Error 0.5317005647812039\n",
      "Meta Train Accuracy 0.8312500063329935\n",
      "Meta Valid Error 0.5902968600858003\n",
      "Meta Valid Accuracy 0.7875000108033419\n",
      "\n",
      "\n",
      "Iteration 256\n",
      "Meta Train Error 0.6243581776507199\n",
      "Meta Train Accuracy 0.7437500120140612\n",
      "Meta Valid Error 0.8009603640530258\n",
      "Meta Valid Accuracy 0.7000000113621354\n",
      "\n",
      "\n",
      "Iteration 288\n",
      "Meta Train Error 0.5663443538360298\n",
      "Meta Train Accuracy 0.7937500081025064\n",
      "Meta Valid Error 0.6819326418917626\n",
      "Meta Valid Accuracy 0.7687500100582838\n",
      "\n",
      "\n",
      "Iteration 320\n",
      "Meta Train Error 0.678454902023077\n",
      "Meta Train Accuracy 0.7500000102445483\n",
      "Meta Valid Error 0.5447123916819692\n",
      "Meta Valid Accuracy 0.8187500084750354\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "\n",
    "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
    "    data, labels = batch\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Separate data into adaptation/evalutation sets\n",
    "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
    "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
    "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
    "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
    "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
    "\n",
    "    # Adapt the model\n",
    "    for step in range(adaptation_steps):\n",
    "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
    "        learner.adapt(train_error)\n",
    "\n",
    "    # Evaluate the adapted model\n",
    "    predictions = learner(evaluation_data)\n",
    "    valid_error = loss(predictions, evaluation_labels)\n",
    "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
    "    return valid_error, valid_accuracy\n",
    "\n",
    "\n",
    "def perform_experiment(\n",
    "        dataset,\n",
    "        ways=5,\n",
    "        shots=1,\n",
    "        meta_lr=0.003,\n",
    "        fast_lr=0.5,\n",
    "        meta_batch_size=32,\n",
    "        adaptation_steps=1,\n",
    "        num_iterations=10000,#60000,\n",
    "        cuda=True,\n",
    "        seed=42,\n",
    "        \n",
    "):\n",
    "    print(\"############### {0} ###############\".format(dataset))\n",
    "    Meta_Train_Accuracy = []\n",
    "    Meta_Train_Error = []\n",
    "    Meta_Val_Accuracy = []\n",
    "    Meta_Val_Error = []\n",
    "#     Iterations = []\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device('cpu')\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    # Load train/validation/test tasksets using the benchmark interface\n",
    "    tasksets = l2l.vision.benchmarks.get_tasksets(dataset,\n",
    "                                                  train_ways=ways,\n",
    "                                                  train_samples=2*shots,\n",
    "                                                  test_ways=ways,\n",
    "                                                  test_samples=2*shots,\n",
    "                                                  num_tasks=20000,\n",
    "                                                  root='~/data',\n",
    "    )\n",
    "\n",
    "    #     \"omniglot\",\n",
    "#             \"mini-imagenet\", \n",
    "#             \"fc100\", \"cifarfs\", \"tiered-imagenet\"\n",
    "    # Create model\n",
    "    if(dataset == \"omniglot\"):\n",
    "        model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
    "    elif(dataset == \"mini-imagenet\"):\n",
    "        model = l2l.vision.models.MiniImagenetCNN(ways)\n",
    "    elif(dataset == \"fc100\"):\n",
    "        features = l2l.vision.models.ConvBase(output_size=64, channels=3, max_pool=True)\n",
    "        features = torch.nn.Sequential(features, Lambda(lambda x: x.view(-1, 256)))\n",
    "        features.to(device)\n",
    "        model = torch.nn.Linear(256, ways)\n",
    "#     elif(dataset = \"\"):\n",
    "    else:\n",
    "        print(\"Error occured.\")\n",
    "        \n",
    "    \n",
    "    model.to(device)\n",
    "    maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
    "    opt = optim.Adam(maml.parameters(), meta_lr)\n",
    "    loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        opt.zero_grad()\n",
    "        meta_train_error = 0.0\n",
    "        meta_train_accuracy = 0.0\n",
    "        meta_valid_error = 0.0\n",
    "        meta_valid_accuracy = 0.0\n",
    "        for task in range(meta_batch_size):\n",
    "            # Compute meta-training loss\n",
    "            learner = maml.clone()\n",
    "            batch = tasksets.train.sample()\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               shots,\n",
    "                                                               ways,\n",
    "                                                               device)\n",
    "            evaluation_error.backward()\n",
    "            meta_train_error += evaluation_error.item()\n",
    "            meta_train_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "            # Compute meta-validation loss\n",
    "            learner = maml.clone()\n",
    "            batch = tasksets.validation.sample()\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               shots,\n",
    "                                                               ways,\n",
    "                                                               device)\n",
    "            meta_valid_error += evaluation_error.item()\n",
    "            meta_valid_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "        # Print some metrics\n",
    "        \n",
    "        \n",
    "        meta_train_error =  meta_train_error / meta_batch_size\n",
    "        meta_train_accuracy = meta_train_accuracy / meta_batch_size\n",
    "        meta_val_error =  meta_valid_error / meta_batch_size\n",
    "        meta_val_accuracy = meta_valid_accuracy / meta_batch_size\n",
    "        if(iteration % 32 ==0):\n",
    "            print('\\n')\n",
    "            print('Iteration', iteration)\n",
    "            print('Meta Train Error', meta_train_error)\n",
    "            print('Meta Train Accuracy', meta_train_accuracy)\n",
    "            print('Meta Valid Error', meta_val_error)\n",
    "            print('Meta Valid Accuracy', meta_val_accuracy)\n",
    "\n",
    "        Meta_Train_Accuracy.append(meta_train_accuracy)\n",
    "        Meta_Train_Error.append(meta_train_error)\n",
    "        Meta_Val_Accuracy.append(meta_val_accuracy)\n",
    "        Meta_Val_Error.append(meta_val_error)\n",
    "\n",
    "        # Average the accumulated gradients and optimize\n",
    "        for p in maml.parameters():\n",
    "            p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "        opt.step()\n",
    "\n",
    "    meta_test_error = 0.0\n",
    "    meta_test_accuracy = 0.0\n",
    "    for task in range(meta_batch_size):\n",
    "        # Compute meta-testing loss\n",
    "        learner = maml.clone()\n",
    "        batch = tasksets.test.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                           learner,\n",
    "                                                           loss,\n",
    "                                                           adaptation_steps,\n",
    "                                                           shots,\n",
    "                                                           ways,\n",
    "                                                           device)\n",
    "        meta_test_error += evaluation_error.item()\n",
    "        meta_test_accuracy += evaluation_accuracy.item()\n",
    "    Meta_Test_Error = meta_test_error / meta_batch_size\n",
    "    print('Meta Test Error', Meta_Test_Error)\n",
    "    Meta_Test_Accuracy = meta_test_accuracy / meta_batch_size\n",
    "    print('Meta Test Accuracy', Meta_Test_Accuracy)\n",
    "    \n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "    if not os.path.exists('plots/acc'):\n",
    "        os.makedirs('plots/acc')\n",
    "    if not os.path.exists('plots/loss'):\n",
    "        os.makedirs('plots/loss')\n",
    "    ###### Plot Accuracies ######\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(list(range(0, len(Meta_Train_Accuracy))), Meta_Train_Accuracy, label=\"Meta Train \")\n",
    "    ax.plot(list(range(0, len(Meta_Val_Accuracy))), Meta_Val_Accuracy, label=\"Meta Val\")\n",
    "#     ax.text((len(Meta_Val_Accuracy)/2), 0, 'Meta Test:{0}'.format(round(meta_test_accuracy, 2)), style='italic',\n",
    "#         bbox={'facecolor': 'red', 'alpha': 0.25, 'pad': 5})\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.05, 0.5, 'Meta Test:{0}'.format(round(Meta_Test_Accuracy, 2)), transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    plt.title('Adaption')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Meta Accuracy')\n",
    "    ax.legend()\n",
    "    plt.savefig('./plots/acc/{0}_ways_{1}_shots_{2}_Acc.png'.format(dataset, ways, shots))\n",
    "    ###### Plot Accuracies ######\n",
    "\n",
    "    ###### Plot Errors ######\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(list(range(0, len(Meta_Train_Error))), Meta_Train_Error, label=\"Meta Train \")\n",
    "    ax.plot(list(range(0, len(Meta_Val_Error))), Meta_Val_Accuracy, label=\"Meta Val Lss\")\n",
    "#     ax.text((len(Meta_Val_Accuracy)/2),0, 'Meta Test Accuracy:{0}  Meta Test Loss:{1}'.format(round(meta_test_accuracy, 2),\n",
    "#                               round(meta_test_error, 2)), style='italic',\n",
    "#         bbox={'facecolor': 'red', 'alpha': 0.25, 'pad': 5})\n",
    "    ax.text(0.05, 0.5, 'MTestAcc:{0}  MTestLoss:{1}'.format(round(Meta_Test_Accuracy, 2),\n",
    "                                           round(Meta_Test_Error, 2)), transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    plt.title('Adaption')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Meta Loss')\n",
    "    ax.legend()\n",
    "    plt.savefig('./plots/loss/{0}_ways_{1}_shots_{2}_Loss_I_{3}.png'.format(dataset, ways, shots, iteration))\n",
    "    ###### Plot Errors ######\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for dataset in Datasets:\n",
    "\n",
    "            \n",
    "        perform_experiment(dataset=dataset,\n",
    "            ways=5,\n",
    "            shots=1,\n",
    "            meta_lr=0.003,\n",
    "            fast_lr=0.5,\n",
    "            meta_batch_size=32,\n",
    "            adaptation_steps=1,\n",
    "            num_iterations=10000,\n",
    "            cuda=True,\n",
    "            seed=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round(12.54673, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.subplot()\n",
    "# ax.plot(list(range(0, (10))), list(range(0, (10))), label=\"Meta Train\")\n",
    "# ax.text(5, 0, 'Meta Test:95%', style='italic',\n",
    "#         bbox={'facecolor': 'red', 'alpha': 0.25, 'pad': 5}, ha='center', va='center')\n",
    "# # ax.plot(list(range(0, len(Meta_Val_Accuracy))), Meta_Val_Accuracy, label=\"Meta Val\")\n",
    "# plt.title('Adaption')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Meta Accuracy')\n",
    "# ax.legend()\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # plt.plot(list(range(0, len(Meta_Train_Accuracy))), Meta_Train_Accuracy,\n",
    "# #         list(range(0, len(Meta_Val_Accuracy))), Meta_Val_Accuracy, label = (\"A\", \"B\"))#, list(range(0, len(Meta_Train_Error))), \n",
    "# #          Meta_Train_Error)#,label = [\"Meta Train Accuracy\", \"Meta Train Error\"])\n",
    "# plt.savefig('foo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(list(range(0, len(Meta_Train_Accuracy))), Meta_Train_Accuracy,\n",
    "#         list(range(0, len(Meta_Val_Accuracy))), Meta_Val_Accuracy, label = (\"A\", \"B\"))#, list(range(0, len(Meta_Train_Error))), \n",
    "# #          Meta_Train_Error)#,label = [\"Meta Train Accuracy\", \"Meta Train Error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
