{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset\n",
    "train_set = torchvision.datasets.MNIST(\"./data\", train=True, download=True,\n",
    "                                   transform=transforms.Compose(\n",
    "                [transforms.ToTensor()]))\n",
    "test_set = torchvision.datasets.MNIST(\"./data\", train=False, download=True)\n",
    "\n",
    "train_set_loader = DataLoader(train_set, batch_size= 128, num_workers=2)\n",
    "test_set_loader = DataLoader(test_set, batch_size=128, num_workers=2)\n",
    "\n",
    "# for indx, x, y in train_set_loader:\n",
    "#     print(indx, len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=9216, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Define Network\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(9216, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "#         print(x.size())\n",
    "        x = x.view(-1, 16 * 24 * 24)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "#         x = F.softmax(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "model = MyNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([[ 0.1069, -0.0569, -0.0434,  0.0415,  0.0406, -0.0196,  0.0426,  0.0221,\n",
      "          0.0152, -0.0718]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1, 1, 28,28))\n",
    "print(x.shape)\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion =nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2304443120956421\n",
      "Loss: 0.4014715850353241\n",
      "Loss: 0.4418361485004425\n",
      "Loss: 0.3108752965927124\n",
      "Loss: 0.26754486560821533\n",
      "Loss: 0.26072078943252563\n",
      "Loss: 0.37420985102653503\n",
      "Loss: 0.2554911971092224\n",
      "Loss: 0.41013747453689575\n",
      "Loss: 0.20458996295928955\n",
      "Loss: 0.33240649104118347\n",
      "Loss: 0.3227280378341675\n",
      "Loss: 0.33724915981292725\n",
      "Loss: 0.18334148824214935\n",
      "Loss: 0.13206960260868073\n",
      "*****************************************************************************************************\n",
      "Loss: 0.17645931243896484\n",
      "Loss: 0.3427405059337616\n",
      "Loss: 0.3721795082092285\n",
      "Loss: 0.24207377433776855\n",
      "Loss: 0.20335835218429565\n",
      "Loss: 0.1916133612394333\n",
      "Loss: 0.2831363081932068\n",
      "Loss: 0.20550407469272614\n",
      "Loss: 0.3420243561267853\n",
      "Loss: 0.17374704778194427\n",
      "Loss: 0.2846646308898926\n",
      "Loss: 0.2515373229980469\n",
      "Loss: 0.2514984607696533\n",
      "Loss: 0.11725575476884842\n",
      "Loss: 0.0920596495270729\n",
      "*****************************************************************************************************\n",
      "Loss: 0.14509451389312744\n",
      "Loss: 0.27948325872421265\n",
      "Loss: 0.3153601586818695\n",
      "Loss: 0.19214561581611633\n",
      "Loss: 0.15297208726406097\n",
      "Loss: 0.14310497045516968\n",
      "Loss: 0.21698293089866638\n",
      "Loss: 0.1604960560798645\n",
      "Loss: 0.29500511288642883\n",
      "Loss: 0.14083871245384216\n",
      "Loss: 0.2434600591659546\n",
      "Loss: 0.20047205686569214\n",
      "Loss: 0.1997605562210083\n",
      "Loss: 0.07377439737319946\n",
      "Loss: 0.06477280706167221\n",
      "*****************************************************************************************************\n",
      "Loss: 0.12221074104309082\n",
      "Loss: 0.22318027913570404\n",
      "Loss: 0.2689990997314453\n",
      "Loss: 0.1520659476518631\n",
      "Loss: 0.11984570324420929\n",
      "Loss: 0.11539417505264282\n",
      "Loss: 0.1711491197347641\n",
      "Loss: 0.12304896116256714\n",
      "Loss: 0.2591864764690399\n",
      "Loss: 0.1106901615858078\n",
      "Loss: 0.20375646650791168\n",
      "Loss: 0.1514633595943451\n",
      "Loss: 0.16403725743293762\n",
      "Loss: 0.04894581064581871\n",
      "Loss: 0.048954498022794724\n",
      "*****************************************************************************************************\n",
      "Loss: 0.10432115942239761\n",
      "Loss: 0.1776672750711441\n",
      "Loss: 0.23233847320079803\n",
      "Loss: 0.11955150961875916\n",
      "Loss: 0.09559435397386551\n",
      "Loss: 0.09947693347930908\n",
      "Loss: 0.14341077208518982\n",
      "Loss: 0.09781777113676071\n",
      "Loss: 0.23155060410499573\n",
      "Loss: 0.08649775385856628\n",
      "Loss: 0.17163841426372528\n",
      "Loss: 0.11586844176054001\n",
      "Loss: 0.13697955012321472\n",
      "Loss: 0.03499586135149002\n",
      "Loss: 0.03946766257286072\n",
      "*****************************************************************************************************\n",
      "Loss: 0.08987006545066833\n",
      "Loss: 0.1422136276960373\n",
      "Loss: 0.20724782347679138\n",
      "Loss: 0.09392120689153671\n",
      "Loss: 0.07488878071308136\n",
      "Loss: 0.09174700081348419\n",
      "Loss: 0.12356043606996536\n",
      "Loss: 0.08148360997438431\n",
      "Loss: 0.21249334514141083\n",
      "Loss: 0.07066280394792557\n",
      "Loss: 0.1459522843360901\n",
      "Loss: 0.0918835997581482\n",
      "Loss: 0.1172756478190422\n",
      "Loss: 0.0269942469894886\n",
      "Loss: 0.03411811590194702\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0785856544971466\n",
      "Loss: 0.11661891639232635\n",
      "Loss: 0.18674837052822113\n",
      "Loss: 0.07490423321723938\n",
      "Loss: 0.059603821486234665\n",
      "Loss: 0.0862489864230156\n",
      "Loss: 0.10787945985794067\n",
      "Loss: 0.0711444765329361\n",
      "Loss: 0.19559359550476074\n",
      "Loss: 0.06069790571928024\n",
      "Loss: 0.12679040431976318\n",
      "Loss: 0.07590627670288086\n",
      "Loss: 0.09877783060073853\n",
      "Loss: 0.021570740267634392\n",
      "Loss: 0.03060082159936428\n",
      "*****************************************************************************************************\n",
      "Loss: 0.06881304830312729\n",
      "Loss: 0.0964970737695694\n",
      "Loss: 0.1691114753484726\n",
      "Loss: 0.0595119372010231\n",
      "Loss: 0.0477365218102932\n",
      "Loss: 0.0824899896979332\n",
      "Loss: 0.09115137159824371\n",
      "Loss: 0.06340859085321426\n",
      "Loss: 0.17901697754859924\n",
      "Loss: 0.05320180952548981\n",
      "Loss: 0.1128818616271019\n",
      "Loss: 0.06473637372255325\n",
      "Loss: 0.08443508297204971\n",
      "Loss: 0.018152864649891853\n",
      "Loss: 0.027391493320465088\n",
      "*****************************************************************************************************\n",
      "Loss: 0.06119761988520622\n",
      "Loss: 0.08278138935565948\n",
      "Loss: 0.15645384788513184\n",
      "Loss: 0.04787022992968559\n",
      "Loss: 0.03687329962849617\n",
      "Loss: 0.07797733694314957\n",
      "Loss: 0.07663077116012573\n",
      "Loss: 0.057654187083244324\n",
      "Loss: 0.16496723890304565\n",
      "Loss: 0.04696745052933693\n",
      "Loss: 0.10400307178497314\n",
      "Loss: 0.05505853891372681\n",
      "Loss: 0.07384374737739563\n",
      "Loss: 0.01498296856880188\n",
      "Loss: 0.02531019039452076\n",
      "*****************************************************************************************************\n",
      "Loss: 0.05500827729701996\n",
      "Loss: 0.07134854048490524\n",
      "Loss: 0.1461353749036789\n",
      "Loss: 0.0387931726872921\n",
      "Loss: 0.028263060376048088\n",
      "Loss: 0.07327280193567276\n",
      "Loss: 0.06414899975061417\n",
      "Loss: 0.05306953936815262\n",
      "Loss: 0.15068411827087402\n",
      "Loss: 0.042371682822704315\n",
      "Loss: 0.09558063745498657\n",
      "Loss: 0.04806012287735939\n",
      "Loss: 0.06517065316438675\n",
      "Loss: 0.013117068447172642\n",
      "Loss: 0.022926630452275276\n",
      "*****************************************************************************************************\n",
      "Loss: 0.04948737472295761\n",
      "Loss: 0.06104276329278946\n",
      "Loss: 0.13698476552963257\n",
      "Loss: 0.03321109712123871\n",
      "Loss: 0.022733652964234352\n",
      "Loss: 0.06747156381607056\n",
      "Loss: 0.05214705690741539\n",
      "Loss: 0.04826780781149864\n",
      "Loss: 0.1341339349746704\n",
      "Loss: 0.038631755858659744\n",
      "Loss: 0.08950966596603394\n",
      "Loss: 0.04301708936691284\n",
      "Loss: 0.057704031467437744\n",
      "Loss: 0.011193542741239071\n",
      "Loss: 0.0215821024030447\n",
      "*****************************************************************************************************\n",
      "Loss: 0.04470425099134445\n",
      "Loss: 0.05433769151568413\n",
      "Loss: 0.129106804728508\n",
      "Loss: 0.027889469638466835\n",
      "Loss: 0.018064307048916817\n",
      "Loss: 0.060523927211761475\n",
      "Loss: 0.04446462541818619\n",
      "Loss: 0.04491066560149193\n",
      "Loss: 0.11960938572883606\n",
      "Loss: 0.0348246805369854\n",
      "Loss: 0.08374260365962982\n",
      "Loss: 0.04032808542251587\n",
      "Loss: 0.051577601581811905\n",
      "Loss: 0.009763114154338837\n",
      "Loss: 0.01947716437280178\n",
      "*****************************************************************************************************\n",
      "Loss: 0.040724750608205795\n",
      "Loss: 0.04837530851364136\n",
      "Loss: 0.12237094342708588\n",
      "Loss: 0.024702921509742737\n",
      "Loss: 0.014962343499064445\n",
      "Loss: 0.05331084877252579\n",
      "Loss: 0.03871597349643707\n",
      "Loss: 0.04010602459311485\n",
      "Loss: 0.1059778705239296\n",
      "Loss: 0.031357817351818085\n",
      "Loss: 0.07760823518037796\n",
      "Loss: 0.0379440002143383\n",
      "Loss: 0.04561196267604828\n",
      "Loss: 0.008291278034448624\n",
      "Loss: 0.018135547637939453\n",
      "*****************************************************************************************************\n",
      "Loss: 0.037274137139320374\n",
      "Loss: 0.04252137988805771\n",
      "Loss: 0.11553841084241867\n",
      "Loss: 0.021800849586725235\n",
      "Loss: 0.012697913683950901\n",
      "Loss: 0.04559829458594322\n",
      "Loss: 0.033942461013793945\n",
      "Loss: 0.035701245069503784\n",
      "Loss: 0.09488561749458313\n",
      "Loss: 0.02836969494819641\n",
      "Loss: 0.07341638952493668\n",
      "Loss: 0.03607981652021408\n",
      "Loss: 0.04103250056505203\n",
      "Loss: 0.006846047937870026\n",
      "Loss: 0.016579680144786835\n",
      "*****************************************************************************************************\n",
      "Loss: 0.03351106494665146\n",
      "Loss: 0.038585055619478226\n",
      "Loss: 0.10834163427352905\n",
      "Loss: 0.02004164457321167\n",
      "Loss: 0.010867576114833355\n",
      "Loss: 0.03947999328374863\n",
      "Loss: 0.03030778467655182\n",
      "Loss: 0.03212090954184532\n",
      "Loss: 0.08344952017068863\n",
      "Loss: 0.025688327848911285\n",
      "Loss: 0.06808706372976303\n",
      "Loss: 0.03378862142562866\n",
      "Loss: 0.0377691388130188\n",
      "Loss: 0.00625075027346611\n",
      "Loss: 0.01488015428185463\n",
      "*****************************************************************************************************\n",
      "Loss: 0.030096637085080147\n",
      "Loss: 0.03408927470445633\n",
      "Loss: 0.10219226032495499\n",
      "Loss: 0.018380392342805862\n",
      "Loss: 0.009416820481419563\n",
      "Loss: 0.033778827637434006\n",
      "Loss: 0.028557784855365753\n",
      "Loss: 0.029164880514144897\n",
      "Loss: 0.07315780967473984\n",
      "Loss: 0.02322036772966385\n",
      "Loss: 0.06282034516334534\n",
      "Loss: 0.032231513410806656\n",
      "Loss: 0.034160319715738297\n",
      "Loss: 0.005676201079040766\n",
      "Loss: 0.01373736560344696\n",
      "*****************************************************************************************************\n",
      "Loss: 0.027169302105903625\n",
      "Loss: 0.030741555616259575\n",
      "Loss: 0.0952424556016922\n",
      "Loss: 0.0167398601770401\n",
      "Loss: 0.008164199069142342\n",
      "Loss: 0.027815677225589752\n",
      "Loss: 0.026040131226181984\n",
      "Loss: 0.025633808225393295\n",
      "Loss: 0.06600525975227356\n",
      "Loss: 0.021171387284994125\n",
      "Loss: 0.05818609520792961\n",
      "Loss: 0.0311287809163332\n",
      "Loss: 0.0316668339073658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0051813554018735886\n",
      "Loss: 0.011984542943537235\n",
      "*****************************************************************************************************\n",
      "Loss: 0.024162622168660164\n",
      "Loss: 0.028642909601330757\n",
      "Loss: 0.08929117023944855\n",
      "Loss: 0.014438423328101635\n",
      "Loss: 0.006981978192925453\n",
      "Loss: 0.02226550132036209\n",
      "Loss: 0.0239567868411541\n",
      "Loss: 0.023440107703208923\n",
      "Loss: 0.061264198273420334\n",
      "Loss: 0.019176840782165527\n",
      "Loss: 0.05324073135852814\n",
      "Loss: 0.02977192960679531\n",
      "Loss: 0.0295840073376894\n",
      "Loss: 0.004799955990165472\n",
      "Loss: 0.010375084355473518\n",
      "*****************************************************************************************************\n",
      "Loss: 0.021776659414172173\n",
      "Loss: 0.025590170174837112\n",
      "Loss: 0.0824725478887558\n",
      "Loss: 0.012789133936166763\n",
      "Loss: 0.0061498344875872135\n",
      "Loss: 0.017877208068966866\n",
      "Loss: 0.02277684211730957\n",
      "Loss: 0.020162655040621758\n",
      "Loss: 0.05568278580904007\n",
      "Loss: 0.01795399934053421\n",
      "Loss: 0.048368409276008606\n",
      "Loss: 0.02898664027452469\n",
      "Loss: 0.0272555872797966\n",
      "Loss: 0.004419623874127865\n",
      "Loss: 0.009099891409277916\n",
      "*****************************************************************************************************\n",
      "Loss: 0.019711969420313835\n",
      "Loss: 0.023528538644313812\n",
      "Loss: 0.07673843950033188\n",
      "Loss: 0.011045142076909542\n",
      "Loss: 0.005229715257883072\n",
      "Loss: 0.014601770788431168\n",
      "Loss: 0.021332306787371635\n",
      "Loss: 0.017992451786994934\n",
      "Loss: 0.052270352840423584\n",
      "Loss: 0.01699717529118061\n",
      "Loss: 0.043457355350255966\n",
      "Loss: 0.02838369458913803\n",
      "Loss: 0.02631598338484764\n",
      "Loss: 0.003857941599562764\n",
      "Loss: 0.008175580762326717\n",
      "*****************************************************************************************************\n",
      "Loss: 0.018301919102668762\n",
      "Loss: 0.021155036985874176\n",
      "Loss: 0.07094065099954605\n",
      "Loss: 0.009321523830294609\n",
      "Loss: 0.004570712801069021\n",
      "Loss: 0.01140192337334156\n",
      "Loss: 0.02049427665770054\n",
      "Loss: 0.016043366864323616\n",
      "Loss: 0.047733742743730545\n",
      "Loss: 0.016114583238959312\n",
      "Loss: 0.039549291133880615\n",
      "Loss: 0.026432227343320847\n",
      "Loss: 0.025057243183255196\n",
      "Loss: 0.0037216730415821075\n",
      "Loss: 0.006905827205628157\n",
      "*****************************************************************************************************\n",
      "Loss: 0.016169873997569084\n",
      "Loss: 0.019490765407681465\n",
      "Loss: 0.06585638970136642\n",
      "Loss: 0.00802619755268097\n",
      "Loss: 0.003954614512622356\n",
      "Loss: 0.009057239629328251\n",
      "Loss: 0.018648764118552208\n",
      "Loss: 0.014583218842744827\n",
      "Loss: 0.04340560734272003\n",
      "Loss: 0.015558375976979733\n",
      "Loss: 0.03301225230097771\n",
      "Loss: 0.024789340794086456\n",
      "Loss: 0.024204837158322334\n",
      "Loss: 0.003367737401276827\n",
      "Loss: 0.00634347228333354\n",
      "*****************************************************************************************************\n",
      "Loss: 0.013972447253763676\n",
      "Loss: 0.017575250938534737\n",
      "Loss: 0.06077836826443672\n",
      "Loss: 0.007038900163024664\n",
      "Loss: 0.003377476939931512\n",
      "Loss: 0.007618797942996025\n",
      "Loss: 0.017585474997758865\n",
      "Loss: 0.012209740467369556\n",
      "Loss: 0.03836623579263687\n",
      "Loss: 0.014527525752782822\n",
      "Loss: 0.027126476168632507\n",
      "Loss: 0.023047227412462234\n",
      "Loss: 0.022399725392460823\n",
      "Loss: 0.00290772900916636\n",
      "Loss: 0.00514950230717659\n",
      "*****************************************************************************************************\n",
      "Loss: 0.012194446288049221\n",
      "Loss: 0.01603293977677822\n",
      "Loss: 0.05646474286913872\n",
      "Loss: 0.0062807658687233925\n",
      "Loss: 0.0030384231358766556\n",
      "Loss: 0.0063403453677892685\n",
      "Loss: 0.01601172424852848\n",
      "Loss: 0.011173314414918423\n",
      "Loss: 0.034947313368320465\n",
      "Loss: 0.013692869804799557\n",
      "Loss: 0.023226838558912277\n",
      "Loss: 0.021294502541422844\n",
      "Loss: 0.020731668919324875\n",
      "Loss: 0.002530698198825121\n",
      "Loss: 0.004667357075959444\n",
      "*****************************************************************************************************\n",
      "Loss: 0.010999378748238087\n",
      "Loss: 0.015228182077407837\n",
      "Loss: 0.05145078897476196\n",
      "Loss: 0.0050678919069468975\n",
      "Loss: 0.002621143590658903\n",
      "Loss: 0.005132939666509628\n",
      "Loss: 0.014800896868109703\n",
      "Loss: 0.01003943383693695\n",
      "Loss: 0.030283397063612938\n",
      "Loss: 0.013289780355989933\n",
      "Loss: 0.0197629202157259\n",
      "Loss: 0.019512925297021866\n",
      "Loss: 0.018697088584303856\n",
      "Loss: 0.0021710412111133337\n",
      "Loss: 0.003999028820544481\n",
      "*****************************************************************************************************\n",
      "Loss: 0.009187974967062473\n",
      "Loss: 0.012886438518762589\n",
      "Loss: 0.04471583664417267\n",
      "Loss: 0.004677881952375174\n",
      "Loss: 0.002400269964709878\n",
      "Loss: 0.00452421884983778\n",
      "Loss: 0.012726468965411186\n",
      "Loss: 0.009989631362259388\n",
      "Loss: 0.02731867879629135\n",
      "Loss: 0.012810834683477879\n",
      "Loss: 0.017580190673470497\n",
      "Loss: 0.01700218766927719\n",
      "Loss: 0.015859482809901237\n",
      "Loss: 0.0019557136110961437\n",
      "Loss: 0.003807684173807502\n",
      "*****************************************************************************************************\n",
      "Loss: 0.007696495391428471\n",
      "Loss: 0.011618518270552158\n",
      "Loss: 0.03987392783164978\n",
      "Loss: 0.0039988975040614605\n",
      "Loss: 0.002158466959372163\n",
      "Loss: 0.0036892315838485956\n",
      "Loss: 0.011391009204089642\n",
      "Loss: 0.008851801976561546\n",
      "Loss: 0.024035096168518066\n",
      "Loss: 0.012523535639047623\n",
      "Loss: 0.015786243602633476\n",
      "Loss: 0.014858817681670189\n",
      "Loss: 0.01427867915481329\n",
      "Loss: 0.0014492712216451764\n",
      "Loss: 0.0032464470714330673\n",
      "*****************************************************************************************************\n",
      "Loss: 0.006567182019352913\n",
      "Loss: 0.010667095892131329\n",
      "Loss: 0.03369094431400299\n",
      "Loss: 0.0034912379924207926\n",
      "Loss: 0.0019463271601125598\n",
      "Loss: 0.0032868541311472654\n",
      "Loss: 0.010206853039562702\n",
      "Loss: 0.007106290198862553\n",
      "Loss: 0.02165713906288147\n",
      "Loss: 0.012176351621747017\n",
      "Loss: 0.012859474867582321\n",
      "Loss: 0.012760062702000141\n",
      "Loss: 0.011824560351669788\n",
      "Loss: 0.0012428543996065855\n",
      "Loss: 0.0031775375828146935\n",
      "*****************************************************************************************************\n",
      "Loss: 0.005469022784382105\n",
      "Loss: 0.009761773981153965\n",
      "Loss: 0.02938213385641575\n",
      "Loss: 0.00308239390142262\n",
      "Loss: 0.0017418479546904564\n",
      "Loss: 0.0026742389891296625\n",
      "Loss: 0.00913679227232933\n",
      "Loss: 0.007021826691925526\n",
      "Loss: 0.019542304798960686\n",
      "Loss: 0.011680864728987217\n",
      "Loss: 0.011187211610376835\n",
      "Loss: 0.009697780013084412\n",
      "Loss: 0.010456318967044353\n",
      "Loss: 0.0012158971512690187\n",
      "Loss: 0.0027199771720916033\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0046818139962852\n",
      "Loss: 0.008695472031831741\n",
      "Loss: 0.022355439141392708\n",
      "Loss: 0.002692572306841612\n",
      "Loss: 0.0015796688385307789\n",
      "Loss: 0.0021812564227730036\n",
      "Loss: 0.008164312690496445\n",
      "Loss: 0.006289286073297262\n",
      "Loss: 0.0182019155472517\n",
      "Loss: 0.01091197319328785\n",
      "Loss: 0.009208153933286667\n",
      "Loss: 0.008908619172871113\n",
      "Loss: 0.008067207410931587\n",
      "Loss: 0.0008812462911009789\n",
      "Loss: 0.002611099975183606\n",
      "*****************************************************************************************************\n",
      "Loss: 0.004145537968724966\n",
      "Loss: 0.008105169981718063\n",
      "Loss: 0.01825316809117794\n",
      "Loss: 0.0022102000657469034\n",
      "Loss: 0.0014158959966152906\n",
      "Loss: 0.001864408259280026\n",
      "Loss: 0.007313673384487629\n",
      "Loss: 0.00581722566857934\n",
      "Loss: 0.015890367329120636\n",
      "Loss: 0.010776424780488014\n",
      "Loss: 0.007672762498259544\n",
      "Loss: 0.006514775566756725\n",
      "Loss: 0.006530145648866892\n",
      "Loss: 0.0007921665674075484\n",
      "Loss: 0.0023734732531011105\n",
      "*****************************************************************************************************\n",
      "Loss: 0.00346461683511734\n",
      "Loss: 0.006704450119286776\n",
      "Loss: 0.014739017002284527\n",
      "Loss: 0.002034862758591771\n",
      "Loss: 0.0012355661019682884\n",
      "Loss: 0.0016144198598340154\n",
      "Loss: 0.00696397153660655\n",
      "Loss: 0.0044791605323553085\n",
      "Loss: 0.014490216970443726\n",
      "Loss: 0.00953978393226862\n",
      "Loss: 0.006765729282051325\n",
      "Loss: 0.004995249677449465\n",
      "Loss: 0.00613232608884573\n",
      "Loss: 0.0007266997126862407\n",
      "Loss: 0.0021610131952911615\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0031056662555783987\n",
      "Loss: 0.00610665837302804\n",
      "Loss: 0.012444287538528442\n",
      "Loss: 0.0015857272082939744\n",
      "Loss: 0.0011062590638175607\n",
      "Loss: 0.00147241132799536\n",
      "Loss: 0.006639203988015652\n",
      "Loss: 0.004557638429105282\n",
      "Loss: 0.0128529267385602\n",
      "Loss: 0.009664787910878658\n",
      "Loss: 0.0061356243677437305\n",
      "Loss: 0.00474972790107131\n",
      "Loss: 0.005594346206635237\n",
      "Loss: 0.000640209938865155\n",
      "Loss: 0.0022785929031670094\n",
      "*****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0026808534748852253\n",
      "Loss: 0.0047990623861551285\n",
      "Loss: 0.009329200722277164\n",
      "Loss: 0.0016209414461627603\n",
      "Loss: 0.0008460156386718154\n",
      "Loss: 0.0012657950865104795\n",
      "Loss: 0.006602470763027668\n",
      "Loss: 0.0042228857055306435\n",
      "Loss: 0.01191147230565548\n",
      "Loss: 0.00910866353660822\n",
      "Loss: 0.0051984298042953014\n",
      "Loss: 0.003724757581949234\n",
      "Loss: 0.0049323635175824165\n",
      "Loss: 0.0007295322138816118\n",
      "Loss: 0.002769649727270007\n",
      "*****************************************************************************************************\n",
      "Loss: 0.002493649022653699\n",
      "Loss: 0.00486077181994915\n",
      "Loss: 0.008380357176065445\n",
      "Loss: 0.001323555945418775\n",
      "Loss: 0.0006179901538416743\n",
      "Loss: 0.0013426184887066483\n",
      "Loss: 0.00559595413506031\n",
      "Loss: 0.0029230802319943905\n",
      "Loss: 0.009828770533204079\n",
      "Loss: 0.007844042964279652\n",
      "Loss: 0.005463659297674894\n",
      "Loss: 0.0028558613266795874\n",
      "Loss: 0.0046917712315917015\n",
      "Loss: 0.0006369343609549105\n",
      "Loss: 0.002179135102778673\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0019910503178834915\n",
      "Loss: 0.004187749698758125\n",
      "Loss: 0.007003975100815296\n",
      "Loss: 0.00123672338668257\n",
      "Loss: 0.0005227400688454509\n",
      "Loss: 0.0010912384605035186\n",
      "Loss: 0.006447140593081713\n",
      "Loss: 0.0024538880679756403\n",
      "Loss: 0.009298907592892647\n",
      "Loss: 0.009197590872645378\n",
      "Loss: 0.00403166888281703\n",
      "Loss: 0.0019691584166139364\n",
      "Loss: 0.004081713035702705\n",
      "Loss: 0.0006926498026587069\n",
      "Loss: 0.0019752185326069593\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0020208063069730997\n",
      "Loss: 0.0036962656304240227\n",
      "Loss: 0.006376327946782112\n",
      "Loss: 0.0011577088152989745\n",
      "Loss: 0.0004173431661911309\n",
      "Loss: 0.00124127056915313\n",
      "Loss: 0.005994649603962898\n",
      "Loss: 0.002207057550549507\n",
      "Loss: 0.007877822034060955\n",
      "Loss: 0.006543342489749193\n",
      "Loss: 0.0038054853212088346\n",
      "Loss: 0.0015084946062415838\n",
      "Loss: 0.003600498428568244\n",
      "Loss: 0.0009372059721499681\n",
      "Loss: 0.0018110815435647964\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0027224875520914793\n",
      "Loss: 0.003624162171036005\n",
      "Loss: 0.005204294808208942\n",
      "Loss: 0.0009602219215594232\n",
      "Loss: 0.00034664315171539783\n",
      "Loss: 0.0010984533000737429\n",
      "Loss: 0.004349082242697477\n",
      "Loss: 0.0026766988448798656\n",
      "Loss: 0.007526637054979801\n",
      "Loss: 0.0066857123747467995\n",
      "Loss: 0.003307623090222478\n",
      "Loss: 0.001102606998756528\n",
      "Loss: 0.003581732278689742\n",
      "Loss: 0.0006557873566634953\n",
      "Loss: 0.0021885493770241737\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0023249865043908358\n",
      "Loss: 0.002432898385450244\n",
      "Loss: 0.004929305985569954\n",
      "Loss: 0.0010058247717097402\n",
      "Loss: 0.0003470943192951381\n",
      "Loss: 0.00127690308727324\n",
      "Loss: 0.004750710912048817\n",
      "Loss: 0.0017405733233317733\n",
      "Loss: 0.006391201168298721\n",
      "Loss: 0.004383374936878681\n",
      "Loss: 0.0037701961118727922\n",
      "Loss: 0.0010134041076526046\n",
      "Loss: 0.004021261818706989\n",
      "Loss: 0.000957696873228997\n",
      "Loss: 0.0014490047469735146\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0028714498039335012\n",
      "Loss: 0.005337546579539776\n",
      "Loss: 0.005085655488073826\n",
      "Loss: 0.0007011386333033442\n",
      "Loss: 0.0002424210251774639\n",
      "Loss: 0.0014971238560974598\n",
      "Loss: 0.0030832826159894466\n",
      "Loss: 0.001810228917747736\n",
      "Loss: 0.006157655268907547\n",
      "Loss: 0.004923701286315918\n",
      "Loss: 0.002852421021088958\n",
      "Loss: 0.000689470034558326\n",
      "Loss: 0.004994703456759453\n",
      "Loss: 0.0005936779780313373\n",
      "Loss: 0.0008870766032487154\n",
      "*****************************************************************************************************\n",
      "Loss: 0.002865998772904277\n",
      "Loss: 0.0033827531151473522\n",
      "Loss: 0.005505320616066456\n",
      "Loss: 0.0007810130482539535\n",
      "Loss: 0.00021034336532466114\n",
      "Loss: 0.0007845092914067209\n",
      "Loss: 0.002575588645413518\n",
      "Loss: 0.0015149044338613749\n",
      "Loss: 0.007943837903439999\n",
      "Loss: 0.003800408449023962\n",
      "Loss: 0.002140018856152892\n",
      "Loss: 0.0009656581096351147\n",
      "Loss: 0.0044110664166510105\n",
      "Loss: 0.0002891169860959053\n",
      "Loss: 0.0005289458204060793\n",
      "*****************************************************************************************************\n",
      "Loss: 0.006220034323632717\n",
      "Loss: 0.0023156055249273777\n",
      "Loss: 0.004870580509305\n",
      "Loss: 0.0005450440803542733\n",
      "Loss: 0.0003294095804449171\n",
      "Loss: 0.0007360223098658025\n",
      "Loss: 0.0022722810972481966\n",
      "Loss: 0.0009380741976201534\n",
      "Loss: 0.004865212365984917\n",
      "Loss: 0.002560265129432082\n",
      "Loss: 0.0022838879376649857\n",
      "Loss: 0.0009351613116450608\n",
      "Loss: 0.00373245682567358\n",
      "Loss: 0.00045911737834103405\n",
      "Loss: 0.0004852768615819514\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0011177276028320193\n",
      "Loss: 0.0051682195626199245\n",
      "Loss: 0.00526415416970849\n",
      "Loss: 0.00042588121141307056\n",
      "Loss: 0.00043140273191966116\n",
      "Loss: 0.0007229101029224694\n",
      "Loss: 0.0014005472185090184\n",
      "Loss: 0.0012642927467823029\n",
      "Loss: 0.003942930139601231\n",
      "Loss: 0.002121087396517396\n",
      "Loss: 0.0021662877406924963\n",
      "Loss: 0.0006013790844008327\n",
      "Loss: 0.0034891976974904537\n",
      "Loss: 0.0004472945583984256\n",
      "Loss: 0.000917105411645025\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0035182780120521784\n",
      "Loss: 0.0013645703438669443\n",
      "Loss: 0.002409938257187605\n",
      "Loss: 0.00027110232622362673\n",
      "Loss: 0.00012626172974705696\n",
      "Loss: 0.0006865756004117429\n",
      "Loss: 0.0023352610878646374\n",
      "Loss: 0.00328946765512228\n",
      "Loss: 0.0026753658894449472\n",
      "Loss: 0.0021924099419265985\n",
      "Loss: 0.003218352794647217\n",
      "Loss: 0.0010107549605891109\n",
      "Loss: 0.0015424118610098958\n",
      "Loss: 0.0011442307149991393\n",
      "Loss: 0.0003040923911612481\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0012115853605791926\n",
      "Loss: 0.0013755257241427898\n",
      "Loss: 0.0034559511113911867\n",
      "Loss: 0.0004286558541934937\n",
      "Loss: 0.00020223212777636945\n",
      "Loss: 0.0003218424681108445\n",
      "Loss: 0.0015043497551232576\n",
      "Loss: 0.0005941010895185173\n",
      "Loss: 0.004570645745843649\n",
      "Loss: 0.00312868133187294\n",
      "Loss: 0.0017867624992504716\n",
      "Loss: 0.003347669029608369\n",
      "Loss: 0.0014792013680562377\n",
      "Loss: 0.0010614068014547229\n",
      "Loss: 0.0002183573233196512\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0006044838228262961\n",
      "Loss: 0.002243761671707034\n",
      "Loss: 0.005456849467009306\n",
      "Loss: 0.0003561687481123954\n",
      "Loss: 0.00018966673815157264\n",
      "Loss: 0.0016226416919380426\n",
      "Loss: 0.001559245167300105\n",
      "Loss: 0.003460260573774576\n",
      "Loss: 0.0043860371224582195\n",
      "Loss: 0.0013381366152316332\n",
      "Loss: 0.0032970868051052094\n",
      "Loss: 0.0011344712693244219\n",
      "Loss: 0.0009992453269660473\n",
      "Loss: 0.0002346184483030811\n",
      "Loss: 0.0002762833028100431\n",
      "*****************************************************************************************************\n",
      "Loss: 0.000345695938449353\n",
      "Loss: 0.0005250502726994455\n",
      "Loss: 0.002664565574377775\n",
      "Loss: 0.00016153932665474713\n",
      "Loss: 0.00027705435059033334\n",
      "Loss: 0.000964009843301028\n",
      "Loss: 0.0027343854308128357\n",
      "Loss: 0.002559064654633403\n",
      "Loss: 0.0027224153745919466\n",
      "Loss: 0.010248688980937004\n",
      "Loss: 0.004122735466808081\n",
      "Loss: 0.0004935932229273021\n",
      "Loss: 0.0012450889917090535\n",
      "Loss: 0.00039941249997355044\n",
      "Loss: 0.0001572172186570242\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0003106111253146082\n",
      "Loss: 0.0007126682321541011\n",
      "Loss: 0.0027174183633178473\n",
      "Loss: 0.00012944237096235156\n",
      "Loss: 0.0002002296387217939\n",
      "Loss: 0.00046666982234455645\n",
      "Loss: 0.002374511444941163\n",
      "Loss: 0.0006352170021273196\n",
      "Loss: 0.003107850905507803\n",
      "Loss: 0.0009928985964506865\n",
      "Loss: 0.0015748939476907253\n",
      "Loss: 0.001587420585565269\n",
      "Loss: 0.005106785800307989\n",
      "Loss: 0.0004946393892168999\n",
      "Loss: 0.00013035236042924225\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0005410696612671018\n",
      "Loss: 0.0009373981738463044\n",
      "Loss: 0.0023016780614852905\n",
      "Loss: 0.0035460807848721743\n",
      "Loss: 0.00014018405636306852\n",
      "Loss: 0.0004338420694693923\n",
      "Loss: 0.0007016021991148591\n",
      "Loss: 0.001312845153734088\n",
      "Loss: 0.002518450142815709\n",
      "Loss: 0.0008853496401570737\n",
      "Loss: 0.0023184434976428747\n",
      "Loss: 0.0023037006612867117\n",
      "Loss: 0.0005752595607191324\n",
      "Loss: 0.00016783081809990108\n",
      "Loss: 0.0002965366293210536\n",
      "*****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004127173451706767\n",
      "Loss: 0.0010393360862508416\n",
      "Loss: 0.001616740133613348\n",
      "Loss: 0.00011678467853926122\n",
      "Loss: 9.407508332515135e-05\n",
      "Loss: 0.00041306164348497987\n",
      "Loss: 0.0011034136405214667\n",
      "Loss: 0.0005265377694740891\n",
      "Loss: 0.0038826323579996824\n",
      "Loss: 0.001013203407637775\n",
      "Loss: 0.007830750197172165\n",
      "Loss: 0.00022231122420635074\n",
      "Loss: 0.0009080214658752084\n",
      "Loss: 0.0001092118545784615\n",
      "Loss: 0.000143490222399123\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0003661442897282541\n",
      "Loss: 0.0006346864975057542\n",
      "Loss: 0.0018047834746539593\n",
      "Loss: 6.324654532363638e-05\n",
      "Loss: 0.0001292101078433916\n",
      "Loss: 0.00017558071704115719\n",
      "Loss: 0.0005715928273275495\n",
      "Loss: 0.0008954054792411625\n",
      "Loss: 0.004063677508383989\n",
      "Loss: 0.0008461916004307568\n",
      "Loss: 0.0028852049726992846\n",
      "Loss: 0.000783915922511369\n",
      "Loss: 0.0005520062404684722\n",
      "Loss: 0.0014351843856275082\n",
      "Loss: 0.0001882297219708562\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0005696699372492731\n",
      "Loss: 0.0007211253978312016\n",
      "Loss: 0.0011505992151796818\n",
      "Loss: 4.0244751289719716e-05\n",
      "Loss: 0.00013341521844267845\n",
      "Loss: 0.00019135601178277284\n",
      "Loss: 0.0004992535104975104\n",
      "Loss: 0.000398462638258934\n",
      "Loss: 0.001331763924099505\n",
      "Loss: 0.00039999562432058156\n",
      "Loss: 0.0010994535405188799\n",
      "Loss: 0.0004918283084407449\n",
      "Loss: 0.0005604837206192315\n",
      "Loss: 0.0002467614540364593\n",
      "Loss: 0.00016676624363753945\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0002740774070844054\n",
      "Loss: 0.0007962004165165126\n",
      "Loss: 0.0010482447687536478\n",
      "Loss: 3.745534922927618e-05\n",
      "Loss: 6.510426464956254e-05\n",
      "Loss: 0.00014523086429107934\n",
      "Loss: 0.00038240908179432154\n",
      "Loss: 0.00033607243676669896\n",
      "Loss: 0.001636483590118587\n",
      "Loss: 0.00031873240368440747\n",
      "Loss: 0.0007870272966101766\n",
      "Loss: 0.0005237573059275746\n",
      "Loss: 0.0005208253278397024\n",
      "Loss: 9.08665606402792e-05\n",
      "Loss: 0.0002507768222130835\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0002113987284246832\n",
      "Loss: 0.0005322668002918363\n",
      "Loss: 0.0009831921197474003\n",
      "Loss: 4.541677481029183e-05\n",
      "Loss: 9.293120092479512e-05\n",
      "Loss: 0.0001679088018136099\n",
      "Loss: 0.00046290858881548047\n",
      "Loss: 0.0002141888689948246\n",
      "Loss: 0.0011650508968159556\n",
      "Loss: 0.00030755012994632125\n",
      "Loss: 0.0007870238623581827\n",
      "Loss: 0.0001869852130766958\n",
      "Loss: 0.0003800539125222713\n",
      "Loss: 0.00014066255243960768\n",
      "Loss: 0.00020702098845504224\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0003115543513558805\n",
      "Loss: 0.0007334827678278089\n",
      "Loss: 0.001023655291646719\n",
      "Loss: 3.830875357380137e-05\n",
      "Loss: 8.421493112109601e-05\n",
      "Loss: 0.00017292978009209037\n",
      "Loss: 0.00039997525163926184\n",
      "Loss: 0.0001942643866641447\n",
      "Loss: 0.0008495248039253056\n",
      "Loss: 0.00024163028865586966\n",
      "Loss: 0.0004552495083771646\n",
      "Loss: 0.0001534379698568955\n",
      "Loss: 0.00037902843905612826\n",
      "Loss: 0.00011317648022668436\n",
      "Loss: 0.00016595171473454684\n",
      "*****************************************************************************************************\n",
      "Loss: 0.00022522895596921444\n",
      "Loss: 0.0004749710496980697\n",
      "Loss: 0.000782776449341327\n",
      "Loss: 4.353291660663672e-05\n",
      "Loss: 8.816064655547962e-05\n",
      "Loss: 0.0001292011293116957\n",
      "Loss: 0.0003856512194033712\n",
      "Loss: 0.0001562842371640727\n",
      "Loss: 0.0006248813588172197\n",
      "Loss: 0.00023278135631699115\n",
      "Loss: 0.00037317993701435626\n",
      "Loss: 0.00011703347990987822\n",
      "Loss: 0.00034470908576622605\n",
      "Loss: 0.00010580545495031402\n",
      "Loss: 0.00014891223690938205\n",
      "*****************************************************************************************************\n",
      "Loss: 0.00021363991254474968\n",
      "Loss: 0.00039704638766124845\n",
      "Loss: 0.0006240449729375541\n",
      "Loss: 4.5076831156620756e-05\n",
      "Loss: 7.459556218236685e-05\n",
      "Loss: 9.70752298599109e-05\n",
      "Loss: 0.00032986252335831523\n",
      "Loss: 0.00012116348079871386\n",
      "Loss: 0.0004936287878081203\n",
      "Loss: 0.0002078032703138888\n",
      "Loss: 0.00034196313936263323\n",
      "Loss: 9.6555108029861e-05\n",
      "Loss: 0.00027754312031902373\n",
      "Loss: 8.177202835213393e-05\n",
      "Loss: 0.00014646838826593012\n",
      "*****************************************************************************************************\n",
      "Loss: 0.00016946790856309235\n",
      "Loss: 0.0002951135684270412\n",
      "Loss: 0.0004644943692255765\n",
      "Loss: 4.2973741074092686e-05\n",
      "Loss: 6.277016655076295e-05\n",
      "Loss: 7.452809222741053e-05\n",
      "Loss: 0.0002605438930913806\n",
      "Loss: 9.610129927750677e-05\n",
      "Loss: 0.0004361802712082863\n",
      "Loss: 0.00018021090363617986\n",
      "Loss: 0.0001144038833444938\n",
      "Loss: 8.231678657466546e-05\n",
      "Loss: 0.00026297845761291683\n",
      "Loss: 6.266201671678573e-05\n",
      "Loss: 9.660772047936916e-05\n",
      "*****************************************************************************************************\n",
      "Loss: 0.00013793926336802542\n",
      "Loss: 0.0002562902227509767\n",
      "Loss: 0.00040169060230255127\n",
      "Loss: 3.240002115489915e-05\n",
      "Loss: 4.7354398702736944e-05\n",
      "Loss: 6.40601065242663e-05\n",
      "Loss: 0.00023576669627800584\n",
      "Loss: 8.46382972667925e-05\n",
      "Loss: 0.00032272370299324393\n",
      "Loss: 0.0001413512072758749\n",
      "Loss: 0.00033148040529340506\n",
      "Loss: 0.0001160586325568147\n",
      "Loss: 0.0002144430036423728\n",
      "Loss: 5.004241393180564e-05\n",
      "Loss: 0.00010471080167917535\n",
      "*****************************************************************************************************\n",
      "Loss: 0.00013685626618098468\n",
      "Loss: 0.0002348961279494688\n",
      "Loss: 0.0003512313705869019\n",
      "Loss: 3.160841151839122e-05\n",
      "Loss: 3.8432674045907333e-05\n",
      "Loss: 4.6929904783610255e-05\n",
      "Loss: 0.00020853718160651624\n",
      "Loss: 6.863460293971002e-05\n",
      "Loss: 0.00027218059403821826\n",
      "Loss: 0.00012309750309213996\n",
      "Loss: 0.00018537700816523284\n",
      "Loss: 0.00014870887389406562\n",
      "Loss: 0.00019772053929045796\n",
      "Loss: 3.737609222298488e-05\n",
      "Loss: 7.818271114956588e-05\n",
      "*****************************************************************************************************\n",
      "Loss: 8.977799734566361e-05\n",
      "Loss: 0.00021872874640394002\n",
      "Loss: 0.00025381753221154213\n",
      "Loss: 2.1996900613885373e-05\n",
      "Loss: 3.365771408425644e-05\n",
      "Loss: 4.563716356642544e-05\n",
      "Loss: 0.0001649052428547293\n",
      "Loss: 5.9620742831612006e-05\n",
      "Loss: 0.00023739119933452457\n",
      "Loss: 0.00012068169598933309\n",
      "Loss: 6.094413765822537e-05\n",
      "Loss: 0.001226874883286655\n",
      "Loss: 0.008953581564128399\n",
      "Loss: 0.00323242275044322\n",
      "Loss: 0.008246839977800846\n",
      "*****************************************************************************************************\n",
      "Loss: 0.001133573823608458\n",
      "Loss: 0.003263437654823065\n",
      "Loss: 0.005328098312020302\n",
      "Loss: 0.0004776689747814089\n",
      "Loss: 0.00022540116333402693\n",
      "Loss: 0.00010402677435195073\n",
      "Loss: 0.001008888939395547\n",
      "Loss: 0.0003507125366013497\n",
      "Loss: 0.0013680558186024427\n",
      "Loss: 0.0003416681429371238\n",
      "Loss: 0.0006499862065538764\n",
      "Loss: 0.00010891887359321117\n",
      "Loss: 0.0018276150804013014\n",
      "Loss: 0.0008352966979146004\n",
      "Loss: 0.00024195511650759727\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0004463136720005423\n",
      "Loss: 0.0007232012576423585\n",
      "Loss: 0.0011561231222003698\n",
      "Loss: 6.592860154341906e-05\n",
      "Loss: 4.467228791327216e-05\n",
      "Loss: 9.266030974686146e-05\n",
      "Loss: 0.0005311011336743832\n",
      "Loss: 0.00012004458403680474\n",
      "Loss: 0.0002694425347726792\n",
      "Loss: 0.0001935218315338716\n",
      "Loss: 0.0007357813301496208\n",
      "Loss: 0.00010495637252461165\n",
      "Loss: 0.0007337017450481653\n",
      "Loss: 8.29832861199975e-05\n",
      "Loss: 8.155981777235866e-05\n",
      "*****************************************************************************************************\n",
      "Loss: 0.0008112980867736042\n",
      "Loss: 0.0005406989366747439\n",
      "Loss: 0.0004208862374071032\n",
      "Loss: 8.817238995106891e-05\n",
      "Loss: 0.0001224635198013857\n",
      "Loss: 4.37688831880223e-05\n",
      "Loss: 0.0003828421176876873\n",
      "Loss: 0.00010319118882762268\n",
      "Loss: 0.00019667966989800334\n",
      "Loss: 0.00024500128347426653\n",
      "Loss: 0.0005910583422519267\n",
      "Loss: 0.00026641643489710987\n",
      "Loss: 0.0002210866950917989\n",
      "Loss: 8.46998009365052e-05\n",
      "Loss: 0.00010079383355332538\n",
      "*****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 64):\n",
    "    for i, (x, y) in enumerate(train_set_loader):\n",
    "#         print(i)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #Forward pass\n",
    "#         print(y)\n",
    "        y_hat = model(x)\n",
    "        #Loss computed\n",
    "        loss = criterion(y_hat, y)\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "        #Optimize\n",
    "        optimizer.step()\n",
    "        if(i % 32 ==0):\n",
    "            print(\"Loss:\", loss.item())\n",
    "    print(\"*\" * 101)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = list(model.parameters())\n",
    "# print(len(params))\n",
    "# print(params[0].size())\n",
    "# print(params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0222,  0.0831,  0.0796, -0.0663,  0.0609, -0.0461, -0.1055, -0.0828,\n",
      "          0.0555, -0.0635]], grad_fn=<AddmmBackward>)\n",
      "<generator object Module.parameters at 0x7fc18f60e5c8>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for l in model.parameters():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0222,  0.0831,  0.0796, -0.0663,  0.0609, -0.0461, -0.1055, -0.0828,\n",
      "          0.0555, -0.0635]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
