{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Demonstrates how to:\n",
    "    * use the MAML wrapper for fast-adaptation,\n",
    "    * use the benchmark interface to load mini-ImageNet, and\n",
    "    * sample tasks and split them in adaptation and evaluation sets.\n",
    "\n",
    "To contrast the use of the benchmark interface with directly instantiating mini-ImageNet datasets and tasks, compare with `protonet_miniimagenet.py`.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data.transforms import (NWays,\n",
    "                                         KShots,\n",
    "                                         LoadData,\n",
    "                                         RemapLabels,\n",
    "                                         ConsecutiveLabels)\n",
    "import os\n",
    "# #Reproducibility\n",
    "seed = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Meta-Dataset\n",
    "ways = 5\n",
    "shots = 1\n",
    "dataset = \"omniglot\"\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available() and torch.cuda.device_count():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "# Create Tasksets using the benchmark interface\n",
    "tasksets = l2l.vision.benchmarks.get_tasksets(dataset,\n",
    "                                              train_samples=shots,#2*shots,\n",
    "                                              train_ways=ways,\n",
    "                                              test_samples=shots,#2*shots,\n",
    "                                              test_ways=ways,\n",
    "                                              root='~/data',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([5, 1, 28, 28])  Y: tensor([1, 3, 2, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "batch = tasksets.train.sample()\n",
    "x, y = batch\n",
    "print(\"X:\", x.shape, \" Y:\", y)\n",
    "# plt.show(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, Linear\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Backbone Network\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1, 3*3*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    \n",
    "class MAML(nn.Module):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def clone(self):\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fast_adapt(self):\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = NN()\n",
    "net2 = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4503, -0.3298],\n",
      "        [-0.1728,  0.5032]])\n",
      "tensor([[-0.4503, -0.3298],\n",
      "        [-0.1728,  0.5032]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "y = x.clone()\n",
    "y.retain_grad()\n",
    "\n",
    "z = y**2\n",
    "z.mean().backward()\n",
    "\n",
    "print(y.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V: tensor([-0.4931, -1.1959,  0.4018], requires_grad=True)\n",
      "V2: tensor([132.4094, 116.7291, 153.8048], grad_fn=<PowBackward0>)\n",
      "V2.Grad: tensor([1., 1., 1.])\n",
      "V1.Grad: tensor([23.0139, 21.6082, 24.8036])\n"
     ]
    }
   ],
   "source": [
    "v = torch.autograd.Variable(torch.randn(3), requires_grad=True)\n",
    "print(\"V:\",v)\n",
    "v2 = (v + 12)**2\n",
    "print(\"V2:\", v2)\n",
    "v2.retain_grad()\n",
    "v2.sum().backward()\n",
    "print(\"V2.Grad:\", v2.grad)\n",
    "print(\"V1.Grad:\", v.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v+1\n",
    "v2.retain_grad()\n",
    "v2.sum().backward()\n",
    "v2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param1: Parameter containing:\n",
      "tensor([[[[ 0.0254, -0.0639,  0.2566],\n",
      "          [-0.0979,  0.1889, -0.2140],\n",
      "          [-0.1157,  0.1258, -0.1244]]]], requires_grad=True)\n",
      "Param2: Parameter containing:\n",
      "tensor([[[[ 0.0254, -0.0639,  0.2566],\n",
      "          [-0.0979,  0.1889, -0.2140],\n",
      "          [-0.1157,  0.1258, -0.1244]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for  params1, params2 in zip(net1.parameters(), net2.parameters()):\n",
    "    params2.data.copy_(params1.data)\n",
    "    print(\"Param1:\", params1)\n",
    "    print(\"Param2:\", params2)\n",
    "    break\n",
    "#     print(params1.data)\n",
    "#     break\n",
    "#     if(params1.data == params2.data):\n",
    "#         print(\"True\")\n",
    "    print(params1.shape, \" : \", params2.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param1: Parameter containing:\n",
      "tensor([[[[ 0.0254, -0.0639,  0.2566],\n",
      "          [-0.0979,  0.1889, -0.2140],\n",
      "          [-0.1157,  0.1258, -0.1244]]]], requires_grad=True)\n",
      "Param2: Parameter containing:\n",
      "tensor([[[[-0.0911, -0.0321,  0.1369],\n",
      "          [-0.1179,  0.0861, -0.3058],\n",
      "          [-0.0653, -0.1240, -0.0681]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "T1: tensor([[ 0.1762, -2.1027],\n",
      "        [ 0.6261,  1.3108]])  \n",
      " T2: tensor([[ 1.2931, -0.3317],\n",
      "        [-0.6834,  0.1683]])\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn((2,2))\n",
    "t2 = torch.randn((2,2))\n",
    "# t2 = t\n",
    "\n",
    "print(\"*\" * 50)\n",
    "print(\"T1:\", t1, \" \\n\", \"T2:\", t2)\n",
    "print(\"*\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: tensor([[ 1.2931, -0.3317],\n",
      "        [-0.6834,  0.1683]])  \n",
      " T2: tensor([[ 1.2931, -0.3317],\n",
      "        [-0.6834,  0.1683]])\n",
      "**************************************************\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# print(\"*\" * 50)\n",
    "# print(\"T1:\", t1, \" \\n\", \"T2:\", t2)\n",
    "# print(\"*\" * 50)\n",
    "print(\"T1:\", t1.data.copy_(t2), \" \\n\", \"T2:\", t2.data)\n",
    "print(\"*\" * 50)\n",
    "print(type(t1.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1: tensor([[ 1.2931, -0.3317],\n",
      "        [-0.6834,  0.1683]])  \n",
      "  T2: tensor([[ 1.2931, -0.3317],\n",
      "        [-0.6834,  0.1683]])\n"
     ]
    }
   ],
   "source": [
    "print(\"T1:\", t1, \" \\n \", \"T2:\", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parameters: Parameter containing:\n",
      "tensor([[[[ 0.2014, -0.1923, -0.0068],\n",
      "          [-0.0415,  0.1986, -0.2086],\n",
      "          [-0.1305,  0.1839,  0.2130]]]], requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[ 0.2014, -0.1923, -0.0068],\n",
      "          [-0.0415,  0.1986, -0.2086],\n",
      "          [-0.1305,  0.1839,  0.2130]]]])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([0.0719], requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([1])\n",
      "tensor([0.0719])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([[[[ 0.0010,  0.0366, -0.0201],\n",
      "          [ 0.0160, -0.0496,  0.0394],\n",
      "          [-0.0354,  0.0353,  0.0176]],\n",
      "\n",
      "         [[-0.0301, -0.0520,  0.0141],\n",
      "          [ 0.0522,  0.0540, -0.0008],\n",
      "          [ 0.0385,  0.0444, -0.0389]],\n",
      "\n",
      "         [[-0.0395,  0.0509, -0.0540],\n",
      "          [-0.0345, -0.0080, -0.0113],\n",
      "          [-0.0586, -0.0114, -0.0058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0129,  0.0008, -0.0302],\n",
      "          [-0.0347, -0.0545,  0.0576],\n",
      "          [-0.0171,  0.0323, -0.0459]],\n",
      "\n",
      "         [[ 0.0053,  0.0218, -0.0240],\n",
      "          [-0.0508,  0.0450, -0.0336],\n",
      "          [-0.0374, -0.0094,  0.0312]],\n",
      "\n",
      "         [[-0.0403, -0.0192, -0.0124],\n",
      "          [-0.0527,  0.0406,  0.0020],\n",
      "          [ 0.0064,  0.0308,  0.0157]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0396, -0.0104, -0.0564],\n",
      "          [-0.0408,  0.0498, -0.0540],\n",
      "          [ 0.0543, -0.0430, -0.0059]],\n",
      "\n",
      "         [[ 0.0401,  0.0321,  0.0242],\n",
      "          [-0.0096,  0.0086, -0.0324],\n",
      "          [-0.0537,  0.0038, -0.0221]],\n",
      "\n",
      "         [[ 0.0408, -0.0541,  0.0165],\n",
      "          [-0.0015,  0.0563, -0.0498],\n",
      "          [-0.0283, -0.0327, -0.0375]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0422,  0.0047, -0.0210],\n",
      "          [-0.0130,  0.0451, -0.0469],\n",
      "          [ 0.0500, -0.0439,  0.0433]],\n",
      "\n",
      "         [[ 0.0574,  0.0479,  0.0453],\n",
      "          [ 0.0378, -0.0088,  0.0470],\n",
      "          [-0.0345,  0.0114, -0.0587]],\n",
      "\n",
      "         [[ 0.0504, -0.0552, -0.0202],\n",
      "          [-0.0252, -0.0015,  0.0013],\n",
      "          [-0.0205, -0.0074, -0.0390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0239,  0.0337, -0.0587],\n",
      "          [-0.0296, -0.0535, -0.0540],\n",
      "          [ 0.0047,  0.0378, -0.0343]],\n",
      "\n",
      "         [[ 0.0255, -0.0182, -0.0486],\n",
      "          [ 0.0189, -0.0138, -0.0374],\n",
      "          [ 0.0165, -0.0073, -0.0381]],\n",
      "\n",
      "         [[-0.0139,  0.0461, -0.0038],\n",
      "          [-0.0057,  0.0542,  0.0299],\n",
      "          [-0.0159,  0.0226, -0.0351]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0017,  0.0327, -0.0065],\n",
      "          [ 0.0289, -0.0482,  0.0187],\n",
      "          [ 0.0439,  0.0445, -0.0479]],\n",
      "\n",
      "         [[-0.0083, -0.0086,  0.0562],\n",
      "          [ 0.0510, -0.0425,  0.0421],\n",
      "          [-0.0562,  0.0141, -0.0126]],\n",
      "\n",
      "         [[-0.0032,  0.0221,  0.0094],\n",
      "          [-0.0396,  0.0199,  0.0202],\n",
      "          [-0.0316,  0.0201,  0.0198]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0198, -0.0516, -0.0527],\n",
      "          [ 0.0423, -0.0207,  0.0121],\n",
      "          [-0.0496,  0.0028,  0.0007]],\n",
      "\n",
      "         [[ 0.0355, -0.0237,  0.0119],\n",
      "          [-0.0382,  0.0081, -0.0126],\n",
      "          [-0.0404,  0.0275,  0.0258]],\n",
      "\n",
      "         [[-0.0114, -0.0244, -0.0328],\n",
      "          [-0.0287, -0.0122,  0.0199],\n",
      "          [-0.0454,  0.0136,  0.0074]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0259, -0.0508, -0.0328],\n",
      "          [-0.0184, -0.0052, -0.0224],\n",
      "          [-0.0004, -0.0166, -0.0202]],\n",
      "\n",
      "         [[ 0.0448, -0.0110,  0.0129],\n",
      "          [-0.0339, -0.0315,  0.0142],\n",
      "          [-0.0019,  0.0047,  0.0244]],\n",
      "\n",
      "         [[-0.0491, -0.0298,  0.0041],\n",
      "          [ 0.0392, -0.0039,  0.0429],\n",
      "          [-0.0137, -0.0267,  0.0340]]],\n",
      "\n",
      "\n",
      "        [[[-0.0529,  0.0283,  0.0059],\n",
      "          [-0.0467, -0.0288,  0.0125],\n",
      "          [-0.0058,  0.0558,  0.0066]],\n",
      "\n",
      "         [[ 0.0066,  0.0355,  0.0187],\n",
      "          [ 0.0405,  0.0107,  0.0522],\n",
      "          [ 0.0349,  0.0287,  0.0386]],\n",
      "\n",
      "         [[ 0.0065, -0.0154, -0.0328],\n",
      "          [-0.0230, -0.0218, -0.0147],\n",
      "          [-0.0198,  0.0227, -0.0525]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0408, -0.0129, -0.0553],\n",
      "          [ 0.0455, -0.0391, -0.0077],\n",
      "          [-0.0188,  0.0083, -0.0079]],\n",
      "\n",
      "         [[-0.0187,  0.0190, -0.0116],\n",
      "          [-0.0347,  0.0110,  0.0495],\n",
      "          [-0.0085,  0.0106, -0.0352]],\n",
      "\n",
      "         [[-0.0190,  0.0373, -0.0060],\n",
      "          [-0.0290, -0.0047, -0.0165],\n",
      "          [-0.0161, -0.0510,  0.0357]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319,  0.0305,  0.0086],\n",
      "          [ 0.0464,  0.0551,  0.0244],\n",
      "          [-0.0360, -0.0549, -0.0266]],\n",
      "\n",
      "         [[-0.0126, -0.0518, -0.0528],\n",
      "          [-0.0334, -0.0462,  0.0245],\n",
      "          [-0.0151, -0.0311,  0.0079]],\n",
      "\n",
      "         [[ 0.0402,  0.0470,  0.0326],\n",
      "          [-0.0343,  0.0495,  0.0276],\n",
      "          [ 0.0173,  0.0361, -0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0286, -0.0365,  0.0164],\n",
      "          [ 0.0542, -0.0164, -0.0178],\n",
      "          [-0.0496,  0.0511,  0.0002]],\n",
      "\n",
      "         [[ 0.0272, -0.0293,  0.0172],\n",
      "          [-0.0085, -0.0094,  0.0459],\n",
      "          [ 0.0289,  0.0246,  0.0220]],\n",
      "\n",
      "         [[ 0.0290, -0.0216, -0.0336],\n",
      "          [ 0.0358,  0.0519, -0.0476],\n",
      "          [-0.0393, -0.0118,  0.0470]]]], requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([32, 32, 3, 3])\n",
      "tensor([[[[ 0.0010,  0.0366, -0.0201],\n",
      "          [ 0.0160, -0.0496,  0.0394],\n",
      "          [-0.0354,  0.0353,  0.0176]],\n",
      "\n",
      "         [[-0.0301, -0.0520,  0.0141],\n",
      "          [ 0.0522,  0.0540, -0.0008],\n",
      "          [ 0.0385,  0.0444, -0.0389]],\n",
      "\n",
      "         [[-0.0395,  0.0509, -0.0540],\n",
      "          [-0.0345, -0.0080, -0.0113],\n",
      "          [-0.0586, -0.0114, -0.0058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0129,  0.0008, -0.0302],\n",
      "          [-0.0347, -0.0545,  0.0576],\n",
      "          [-0.0171,  0.0323, -0.0459]],\n",
      "\n",
      "         [[ 0.0053,  0.0218, -0.0240],\n",
      "          [-0.0508,  0.0450, -0.0336],\n",
      "          [-0.0374, -0.0094,  0.0312]],\n",
      "\n",
      "         [[-0.0403, -0.0192, -0.0124],\n",
      "          [-0.0527,  0.0406,  0.0020],\n",
      "          [ 0.0064,  0.0308,  0.0157]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0396, -0.0104, -0.0564],\n",
      "          [-0.0408,  0.0498, -0.0540],\n",
      "          [ 0.0543, -0.0430, -0.0059]],\n",
      "\n",
      "         [[ 0.0401,  0.0321,  0.0242],\n",
      "          [-0.0096,  0.0086, -0.0324],\n",
      "          [-0.0537,  0.0038, -0.0221]],\n",
      "\n",
      "         [[ 0.0408, -0.0541,  0.0165],\n",
      "          [-0.0015,  0.0563, -0.0498],\n",
      "          [-0.0283, -0.0327, -0.0375]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0422,  0.0047, -0.0210],\n",
      "          [-0.0130,  0.0451, -0.0469],\n",
      "          [ 0.0500, -0.0439,  0.0433]],\n",
      "\n",
      "         [[ 0.0574,  0.0479,  0.0453],\n",
      "          [ 0.0378, -0.0088,  0.0470],\n",
      "          [-0.0345,  0.0114, -0.0587]],\n",
      "\n",
      "         [[ 0.0504, -0.0552, -0.0202],\n",
      "          [-0.0252, -0.0015,  0.0013],\n",
      "          [-0.0205, -0.0074, -0.0390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0239,  0.0337, -0.0587],\n",
      "          [-0.0296, -0.0535, -0.0540],\n",
      "          [ 0.0047,  0.0378, -0.0343]],\n",
      "\n",
      "         [[ 0.0255, -0.0182, -0.0486],\n",
      "          [ 0.0189, -0.0138, -0.0374],\n",
      "          [ 0.0165, -0.0073, -0.0381]],\n",
      "\n",
      "         [[-0.0139,  0.0461, -0.0038],\n",
      "          [-0.0057,  0.0542,  0.0299],\n",
      "          [-0.0159,  0.0226, -0.0351]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0017,  0.0327, -0.0065],\n",
      "          [ 0.0289, -0.0482,  0.0187],\n",
      "          [ 0.0439,  0.0445, -0.0479]],\n",
      "\n",
      "         [[-0.0083, -0.0086,  0.0562],\n",
      "          [ 0.0510, -0.0425,  0.0421],\n",
      "          [-0.0562,  0.0141, -0.0126]],\n",
      "\n",
      "         [[-0.0032,  0.0221,  0.0094],\n",
      "          [-0.0396,  0.0199,  0.0202],\n",
      "          [-0.0316,  0.0201,  0.0198]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0198, -0.0516, -0.0527],\n",
      "          [ 0.0423, -0.0207,  0.0121],\n",
      "          [-0.0496,  0.0028,  0.0007]],\n",
      "\n",
      "         [[ 0.0355, -0.0237,  0.0119],\n",
      "          [-0.0382,  0.0081, -0.0126],\n",
      "          [-0.0404,  0.0275,  0.0258]],\n",
      "\n",
      "         [[-0.0114, -0.0244, -0.0328],\n",
      "          [-0.0287, -0.0122,  0.0199],\n",
      "          [-0.0454,  0.0136,  0.0074]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0259, -0.0508, -0.0328],\n",
      "          [-0.0184, -0.0052, -0.0224],\n",
      "          [-0.0004, -0.0166, -0.0202]],\n",
      "\n",
      "         [[ 0.0448, -0.0110,  0.0129],\n",
      "          [-0.0339, -0.0315,  0.0142],\n",
      "          [-0.0019,  0.0047,  0.0244]],\n",
      "\n",
      "         [[-0.0491, -0.0298,  0.0041],\n",
      "          [ 0.0392, -0.0039,  0.0429],\n",
      "          [-0.0137, -0.0267,  0.0340]]],\n",
      "\n",
      "\n",
      "        [[[-0.0529,  0.0283,  0.0059],\n",
      "          [-0.0467, -0.0288,  0.0125],\n",
      "          [-0.0058,  0.0558,  0.0066]],\n",
      "\n",
      "         [[ 0.0066,  0.0355,  0.0187],\n",
      "          [ 0.0405,  0.0107,  0.0522],\n",
      "          [ 0.0349,  0.0287,  0.0386]],\n",
      "\n",
      "         [[ 0.0065, -0.0154, -0.0328],\n",
      "          [-0.0230, -0.0218, -0.0147],\n",
      "          [-0.0198,  0.0227, -0.0525]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0408, -0.0129, -0.0553],\n",
      "          [ 0.0455, -0.0391, -0.0077],\n",
      "          [-0.0188,  0.0083, -0.0079]],\n",
      "\n",
      "         [[-0.0187,  0.0190, -0.0116],\n",
      "          [-0.0347,  0.0110,  0.0495],\n",
      "          [-0.0085,  0.0106, -0.0352]],\n",
      "\n",
      "         [[-0.0190,  0.0373, -0.0060],\n",
      "          [-0.0290, -0.0047, -0.0165],\n",
      "          [-0.0161, -0.0510,  0.0357]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319,  0.0305,  0.0086],\n",
      "          [ 0.0464,  0.0551,  0.0244],\n",
      "          [-0.0360, -0.0549, -0.0266]],\n",
      "\n",
      "         [[-0.0126, -0.0518, -0.0528],\n",
      "          [-0.0334, -0.0462,  0.0245],\n",
      "          [-0.0151, -0.0311,  0.0079]],\n",
      "\n",
      "         [[ 0.0402,  0.0470,  0.0326],\n",
      "          [-0.0343,  0.0495,  0.0276],\n",
      "          [ 0.0173,  0.0361, -0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0286, -0.0365,  0.0164],\n",
      "          [ 0.0542, -0.0164, -0.0178],\n",
      "          [-0.0496,  0.0511,  0.0002]],\n",
      "\n",
      "         [[ 0.0272, -0.0293,  0.0172],\n",
      "          [-0.0085, -0.0094,  0.0459],\n",
      "          [ 0.0289,  0.0246,  0.0220]],\n",
      "\n",
      "         [[ 0.0290, -0.0216, -0.0336],\n",
      "          [ 0.0358,  0.0519, -0.0476],\n",
      "          [-0.0393, -0.0118,  0.0470]]]])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([ 0.0390,  0.0226, -0.0161, -0.0055,  0.0474, -0.0507, -0.0484,  0.0145,\n",
      "        -0.0222,  0.0185, -0.0586, -0.0184, -0.0100,  0.0333, -0.0509,  0.0117,\n",
      "         0.0060,  0.0337, -0.0461,  0.0240, -0.0472, -0.0307,  0.0267, -0.0033,\n",
      "        -0.0326, -0.0260, -0.0064, -0.0431, -0.0335,  0.0332, -0.0376,  0.0242],\n",
      "       requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([32])\n",
      "tensor([ 0.0390,  0.0226, -0.0161, -0.0055,  0.0474, -0.0507, -0.0484,  0.0145,\n",
      "        -0.0222,  0.0185, -0.0586, -0.0184, -0.0100,  0.0333, -0.0509,  0.0117,\n",
      "         0.0060,  0.0337, -0.0461,  0.0240, -0.0472, -0.0307,  0.0267, -0.0033,\n",
      "        -0.0326, -0.0260, -0.0064, -0.0431, -0.0335,  0.0332, -0.0376,  0.0242])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([[[[ 0.0575,  0.0191, -0.0517],\n",
      "          [-0.0203, -0.0012, -0.0349],\n",
      "          [ 0.0539, -0.0117, -0.0505]],\n",
      "\n",
      "         [[-0.0568, -0.0167, -0.0104],\n",
      "          [ 0.0411, -0.0149, -0.0291],\n",
      "          [ 0.0107,  0.0454, -0.0169]],\n",
      "\n",
      "         [[ 0.0149, -0.0076, -0.0352],\n",
      "          [ 0.0276,  0.0084,  0.0424],\n",
      "          [-0.0123, -0.0527,  0.0487]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0553, -0.0193,  0.0459],\n",
      "          [-0.0237, -0.0581, -0.0139],\n",
      "          [-0.0033,  0.0109, -0.0513]],\n",
      "\n",
      "         [[-0.0029,  0.0474,  0.0498],\n",
      "          [ 0.0112, -0.0262, -0.0444],\n",
      "          [-0.0031,  0.0210, -0.0417]],\n",
      "\n",
      "         [[ 0.0015,  0.0397,  0.0522],\n",
      "          [-0.0424, -0.0325,  0.0260],\n",
      "          [ 0.0186, -0.0502,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0204,  0.0585,  0.0349],\n",
      "          [-0.0083,  0.0143, -0.0155],\n",
      "          [ 0.0526, -0.0190,  0.0139]],\n",
      "\n",
      "         [[-0.0281, -0.0363, -0.0074],\n",
      "          [-0.0282, -0.0312,  0.0588],\n",
      "          [ 0.0525, -0.0169, -0.0276]],\n",
      "\n",
      "         [[ 0.0137,  0.0517,  0.0018],\n",
      "          [ 0.0172,  0.0166,  0.0007],\n",
      "          [-0.0424,  0.0191, -0.0551]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0247,  0.0243, -0.0452],\n",
      "          [ 0.0567, -0.0034,  0.0495],\n",
      "          [ 0.0224, -0.0133, -0.0279]],\n",
      "\n",
      "         [[ 0.0329,  0.0450,  0.0114],\n",
      "          [ 0.0378, -0.0355,  0.0453],\n",
      "          [ 0.0140,  0.0396,  0.0518]],\n",
      "\n",
      "         [[-0.0044,  0.0269,  0.0170],\n",
      "          [ 0.0446, -0.0572, -0.0057],\n",
      "          [-0.0132,  0.0240, -0.0295]]],\n",
      "\n",
      "\n",
      "        [[[-0.0239, -0.0530,  0.0047],\n",
      "          [ 0.0587, -0.0480, -0.0449],\n",
      "          [-0.0548, -0.0259, -0.0463]],\n",
      "\n",
      "         [[-0.0314,  0.0242,  0.0511],\n",
      "          [-0.0133,  0.0453, -0.0549],\n",
      "          [ 0.0171,  0.0193, -0.0071]],\n",
      "\n",
      "         [[-0.0190, -0.0060,  0.0074],\n",
      "          [-0.0267,  0.0295,  0.0573],\n",
      "          [-0.0527,  0.0064,  0.0295]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0580,  0.0214,  0.0290],\n",
      "          [ 0.0277, -0.0261, -0.0458],\n",
      "          [-0.0129,  0.0068,  0.0477]],\n",
      "\n",
      "         [[-0.0495,  0.0228, -0.0119],\n",
      "          [-0.0220, -0.0017, -0.0549],\n",
      "          [-0.0249, -0.0286,  0.0022]],\n",
      "\n",
      "         [[-0.0509,  0.0576,  0.0270],\n",
      "          [ 0.0386, -0.0386, -0.0149],\n",
      "          [ 0.0556, -0.0214,  0.0336]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0261,  0.0061, -0.0527],\n",
      "          [ 0.0539, -0.0308,  0.0219],\n",
      "          [-0.0538,  0.0152,  0.0329]],\n",
      "\n",
      "         [[ 0.0358,  0.0340,  0.0589],\n",
      "          [-0.0165, -0.0579, -0.0297],\n",
      "          [ 0.0237, -0.0501, -0.0222]],\n",
      "\n",
      "         [[ 0.0495,  0.0440, -0.0169],\n",
      "          [-0.0022, -0.0098,  0.0078],\n",
      "          [-0.0502,  0.0459, -0.0005]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0351,  0.0514,  0.0551],\n",
      "          [ 0.0497,  0.0581, -0.0385],\n",
      "          [-0.0223,  0.0489,  0.0144]],\n",
      "\n",
      "         [[-0.0538,  0.0439,  0.0252],\n",
      "          [ 0.0192, -0.0100, -0.0219],\n",
      "          [-0.0381, -0.0370, -0.0065]],\n",
      "\n",
      "         [[ 0.0186,  0.0082, -0.0118],\n",
      "          [ 0.0215,  0.0397,  0.0570],\n",
      "          [-0.0177, -0.0551,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[-0.0338,  0.0442, -0.0245],\n",
      "          [ 0.0373,  0.0461, -0.0056],\n",
      "          [ 0.0065,  0.0564,  0.0444]],\n",
      "\n",
      "         [[ 0.0545, -0.0187,  0.0079],\n",
      "          [-0.0007, -0.0224, -0.0275],\n",
      "          [-0.0142,  0.0541,  0.0012]],\n",
      "\n",
      "         [[-0.0121, -0.0026,  0.0001],\n",
      "          [ 0.0111,  0.0485,  0.0587],\n",
      "          [-0.0234,  0.0463,  0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0299, -0.0219, -0.0102],\n",
      "          [ 0.0506, -0.0152, -0.0465],\n",
      "          [ 0.0504, -0.0255,  0.0461]],\n",
      "\n",
      "         [[ 0.0582,  0.0265, -0.0096],\n",
      "          [-0.0305, -0.0066,  0.0545],\n",
      "          [ 0.0424, -0.0140,  0.0183]],\n",
      "\n",
      "         [[ 0.0071, -0.0342, -0.0396],\n",
      "          [-0.0021,  0.0216,  0.0085],\n",
      "          [ 0.0350, -0.0259, -0.0588]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0126,  0.0211,  0.0587],\n",
      "          [ 0.0200,  0.0161, -0.0268],\n",
      "          [ 0.0453, -0.0509, -0.0305]],\n",
      "\n",
      "         [[-0.0228,  0.0038,  0.0333],\n",
      "          [-0.0441,  0.0052,  0.0475],\n",
      "          [-0.0420, -0.0461, -0.0007]],\n",
      "\n",
      "         [[ 0.0448, -0.0374,  0.0470],\n",
      "          [-0.0317,  0.0313, -0.0426],\n",
      "          [-0.0154,  0.0305,  0.0509]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0440, -0.0103, -0.0340],\n",
      "          [-0.0412, -0.0330,  0.0139],\n",
      "          [ 0.0589, -0.0079, -0.0212]],\n",
      "\n",
      "         [[ 0.0057, -0.0558,  0.0359],\n",
      "          [-0.0529,  0.0409,  0.0060],\n",
      "          [-0.0127, -0.0198, -0.0012]],\n",
      "\n",
      "         [[-0.0155, -0.0367, -0.0039],\n",
      "          [-0.0214, -0.0261,  0.0475],\n",
      "          [ 0.0529, -0.0366, -0.0274]]]], requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([64, 32, 3, 3])\n",
      "tensor([[[[ 0.0575,  0.0191, -0.0517],\n",
      "          [-0.0203, -0.0012, -0.0349],\n",
      "          [ 0.0539, -0.0117, -0.0505]],\n",
      "\n",
      "         [[-0.0568, -0.0167, -0.0104],\n",
      "          [ 0.0411, -0.0149, -0.0291],\n",
      "          [ 0.0107,  0.0454, -0.0169]],\n",
      "\n",
      "         [[ 0.0149, -0.0076, -0.0352],\n",
      "          [ 0.0276,  0.0084,  0.0424],\n",
      "          [-0.0123, -0.0527,  0.0487]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0553, -0.0193,  0.0459],\n",
      "          [-0.0237, -0.0581, -0.0139],\n",
      "          [-0.0033,  0.0109, -0.0513]],\n",
      "\n",
      "         [[-0.0029,  0.0474,  0.0498],\n",
      "          [ 0.0112, -0.0262, -0.0444],\n",
      "          [-0.0031,  0.0210, -0.0417]],\n",
      "\n",
      "         [[ 0.0015,  0.0397,  0.0522],\n",
      "          [-0.0424, -0.0325,  0.0260],\n",
      "          [ 0.0186, -0.0502,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0204,  0.0585,  0.0349],\n",
      "          [-0.0083,  0.0143, -0.0155],\n",
      "          [ 0.0526, -0.0190,  0.0139]],\n",
      "\n",
      "         [[-0.0281, -0.0363, -0.0074],\n",
      "          [-0.0282, -0.0312,  0.0588],\n",
      "          [ 0.0525, -0.0169, -0.0276]],\n",
      "\n",
      "         [[ 0.0137,  0.0517,  0.0018],\n",
      "          [ 0.0172,  0.0166,  0.0007],\n",
      "          [-0.0424,  0.0191, -0.0551]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0247,  0.0243, -0.0452],\n",
      "          [ 0.0567, -0.0034,  0.0495],\n",
      "          [ 0.0224, -0.0133, -0.0279]],\n",
      "\n",
      "         [[ 0.0329,  0.0450,  0.0114],\n",
      "          [ 0.0378, -0.0355,  0.0453],\n",
      "          [ 0.0140,  0.0396,  0.0518]],\n",
      "\n",
      "         [[-0.0044,  0.0269,  0.0170],\n",
      "          [ 0.0446, -0.0572, -0.0057],\n",
      "          [-0.0132,  0.0240, -0.0295]]],\n",
      "\n",
      "\n",
      "        [[[-0.0239, -0.0530,  0.0047],\n",
      "          [ 0.0587, -0.0480, -0.0449],\n",
      "          [-0.0548, -0.0259, -0.0463]],\n",
      "\n",
      "         [[-0.0314,  0.0242,  0.0511],\n",
      "          [-0.0133,  0.0453, -0.0549],\n",
      "          [ 0.0171,  0.0193, -0.0071]],\n",
      "\n",
      "         [[-0.0190, -0.0060,  0.0074],\n",
      "          [-0.0267,  0.0295,  0.0573],\n",
      "          [-0.0527,  0.0064,  0.0295]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0580,  0.0214,  0.0290],\n",
      "          [ 0.0277, -0.0261, -0.0458],\n",
      "          [-0.0129,  0.0068,  0.0477]],\n",
      "\n",
      "         [[-0.0495,  0.0228, -0.0119],\n",
      "          [-0.0220, -0.0017, -0.0549],\n",
      "          [-0.0249, -0.0286,  0.0022]],\n",
      "\n",
      "         [[-0.0509,  0.0576,  0.0270],\n",
      "          [ 0.0386, -0.0386, -0.0149],\n",
      "          [ 0.0556, -0.0214,  0.0336]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0261,  0.0061, -0.0527],\n",
      "          [ 0.0539, -0.0308,  0.0219],\n",
      "          [-0.0538,  0.0152,  0.0329]],\n",
      "\n",
      "         [[ 0.0358,  0.0340,  0.0589],\n",
      "          [-0.0165, -0.0579, -0.0297],\n",
      "          [ 0.0237, -0.0501, -0.0222]],\n",
      "\n",
      "         [[ 0.0495,  0.0440, -0.0169],\n",
      "          [-0.0022, -0.0098,  0.0078],\n",
      "          [-0.0502,  0.0459, -0.0005]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0351,  0.0514,  0.0551],\n",
      "          [ 0.0497,  0.0581, -0.0385],\n",
      "          [-0.0223,  0.0489,  0.0144]],\n",
      "\n",
      "         [[-0.0538,  0.0439,  0.0252],\n",
      "          [ 0.0192, -0.0100, -0.0219],\n",
      "          [-0.0381, -0.0370, -0.0065]],\n",
      "\n",
      "         [[ 0.0186,  0.0082, -0.0118],\n",
      "          [ 0.0215,  0.0397,  0.0570],\n",
      "          [-0.0177, -0.0551,  0.0088]]],\n",
      "\n",
      "\n",
      "        [[[-0.0338,  0.0442, -0.0245],\n",
      "          [ 0.0373,  0.0461, -0.0056],\n",
      "          [ 0.0065,  0.0564,  0.0444]],\n",
      "\n",
      "         [[ 0.0545, -0.0187,  0.0079],\n",
      "          [-0.0007, -0.0224, -0.0275],\n",
      "          [-0.0142,  0.0541,  0.0012]],\n",
      "\n",
      "         [[-0.0121, -0.0026,  0.0001],\n",
      "          [ 0.0111,  0.0485,  0.0587],\n",
      "          [-0.0234,  0.0463,  0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0299, -0.0219, -0.0102],\n",
      "          [ 0.0506, -0.0152, -0.0465],\n",
      "          [ 0.0504, -0.0255,  0.0461]],\n",
      "\n",
      "         [[ 0.0582,  0.0265, -0.0096],\n",
      "          [-0.0305, -0.0066,  0.0545],\n",
      "          [ 0.0424, -0.0140,  0.0183]],\n",
      "\n",
      "         [[ 0.0071, -0.0342, -0.0396],\n",
      "          [-0.0021,  0.0216,  0.0085],\n",
      "          [ 0.0350, -0.0259, -0.0588]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0126,  0.0211,  0.0587],\n",
      "          [ 0.0200,  0.0161, -0.0268],\n",
      "          [ 0.0453, -0.0509, -0.0305]],\n",
      "\n",
      "         [[-0.0228,  0.0038,  0.0333],\n",
      "          [-0.0441,  0.0052,  0.0475],\n",
      "          [-0.0420, -0.0461, -0.0007]],\n",
      "\n",
      "         [[ 0.0448, -0.0374,  0.0470],\n",
      "          [-0.0317,  0.0313, -0.0426],\n",
      "          [-0.0154,  0.0305,  0.0509]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0440, -0.0103, -0.0340],\n",
      "          [-0.0412, -0.0330,  0.0139],\n",
      "          [ 0.0589, -0.0079, -0.0212]],\n",
      "\n",
      "         [[ 0.0057, -0.0558,  0.0359],\n",
      "          [-0.0529,  0.0409,  0.0060],\n",
      "          [-0.0127, -0.0198, -0.0012]],\n",
      "\n",
      "         [[-0.0155, -0.0367, -0.0039],\n",
      "          [-0.0214, -0.0261,  0.0475],\n",
      "          [ 0.0529, -0.0366, -0.0274]]]])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([-0.0523, -0.0102, -0.0488,  0.0575,  0.0535, -0.0211, -0.0254,  0.0546,\n",
      "         0.0022, -0.0077,  0.0016,  0.0528, -0.0292,  0.0008, -0.0088,  0.0314,\n",
      "        -0.0346,  0.0124, -0.0540, -0.0182,  0.0548,  0.0174,  0.0588,  0.0172,\n",
      "         0.0343, -0.0384,  0.0442,  0.0357,  0.0164, -0.0250,  0.0322,  0.0517,\n",
      "        -0.0306,  0.0349,  0.0081, -0.0328,  0.0464,  0.0145, -0.0532, -0.0224,\n",
      "         0.0563, -0.0140,  0.0403, -0.0501, -0.0241, -0.0308,  0.0529, -0.0168,\n",
      "         0.0197, -0.0181,  0.0045, -0.0386, -0.0353,  0.0071,  0.0165,  0.0058,\n",
      "         0.0273, -0.0091,  0.0154, -0.0513, -0.0069,  0.0252, -0.0454,  0.0277],\n",
      "       requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([64])\n",
      "tensor([-0.0523, -0.0102, -0.0488,  0.0575,  0.0535, -0.0211, -0.0254,  0.0546,\n",
      "         0.0022, -0.0077,  0.0016,  0.0528, -0.0292,  0.0008, -0.0088,  0.0314,\n",
      "        -0.0346,  0.0124, -0.0540, -0.0182,  0.0548,  0.0174,  0.0588,  0.0172,\n",
      "         0.0343, -0.0384,  0.0442,  0.0357,  0.0164, -0.0250,  0.0322,  0.0517,\n",
      "        -0.0306,  0.0349,  0.0081, -0.0328,  0.0464,  0.0145, -0.0532, -0.0224,\n",
      "         0.0563, -0.0140,  0.0403, -0.0501, -0.0241, -0.0308,  0.0529, -0.0168,\n",
      "         0.0197, -0.0181,  0.0045, -0.0386, -0.0353,  0.0071,  0.0165,  0.0058,\n",
      "         0.0273, -0.0091,  0.0154, -0.0513, -0.0069,  0.0252, -0.0454,  0.0277])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([[ 0.0246,  0.0317,  0.0103,  ...,  0.0294, -0.0189,  0.0156],\n",
      "        [ 0.0068, -0.0119,  0.0105,  ..., -0.0060,  0.0140,  0.0090],\n",
      "        [-0.0162,  0.0132,  0.0262,  ..., -0.0259,  0.0185,  0.0017],\n",
      "        ...,\n",
      "        [ 0.0074,  0.0243, -0.0169,  ..., -0.0025, -0.0330,  0.0088],\n",
      "        [-0.0406, -0.0384, -0.0241,  ...,  0.0154,  0.0159, -0.0075],\n",
      "        [-0.0340,  0.0207, -0.0415,  ...,  0.0297,  0.0295, -0.0032]],\n",
      "       requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([256, 576])\n",
      "tensor([[ 0.0246,  0.0317,  0.0103,  ...,  0.0294, -0.0189,  0.0156],\n",
      "        [ 0.0068, -0.0119,  0.0105,  ..., -0.0060,  0.0140,  0.0090],\n",
      "        [-0.0162,  0.0132,  0.0262,  ..., -0.0259,  0.0185,  0.0017],\n",
      "        ...,\n",
      "        [ 0.0074,  0.0243, -0.0169,  ..., -0.0025, -0.0330,  0.0088],\n",
      "        [-0.0406, -0.0384, -0.0241,  ...,  0.0154,  0.0159, -0.0075],\n",
      "        [-0.0340,  0.0207, -0.0415,  ...,  0.0297,  0.0295, -0.0032]])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([ 0.0172, -0.0398,  0.0409, -0.0300,  0.0114,  0.0064,  0.0217, -0.0028,\n",
      "        -0.0082,  0.0162, -0.0158, -0.0037,  0.0349,  0.0330, -0.0374,  0.0361,\n",
      "        -0.0042,  0.0387,  0.0364,  0.0144,  0.0109,  0.0328,  0.0257,  0.0148,\n",
      "        -0.0409, -0.0300,  0.0314, -0.0344, -0.0234, -0.0082, -0.0217, -0.0282,\n",
      "        -0.0097,  0.0057, -0.0030,  0.0362,  0.0296,  0.0246,  0.0214,  0.0107,\n",
      "        -0.0220,  0.0230,  0.0070, -0.0410, -0.0207,  0.0072, -0.0291, -0.0362,\n",
      "         0.0413, -0.0185,  0.0393,  0.0341, -0.0365,  0.0268,  0.0214,  0.0096,\n",
      "        -0.0282,  0.0322,  0.0100, -0.0213, -0.0331, -0.0321, -0.0031,  0.0187,\n",
      "         0.0171,  0.0347,  0.0105, -0.0402, -0.0220, -0.0187, -0.0235,  0.0031,\n",
      "         0.0018,  0.0156, -0.0049, -0.0075,  0.0346, -0.0164, -0.0055,  0.0134,\n",
      "         0.0245,  0.0183,  0.0154,  0.0083, -0.0288, -0.0229,  0.0271, -0.0224,\n",
      "        -0.0272, -0.0281, -0.0160, -0.0334, -0.0199,  0.0348,  0.0253, -0.0298,\n",
      "         0.0283,  0.0362,  0.0113,  0.0304,  0.0324,  0.0177, -0.0325,  0.0147,\n",
      "        -0.0333,  0.0206,  0.0416,  0.0175,  0.0027, -0.0366,  0.0023,  0.0124,\n",
      "        -0.0190,  0.0090, -0.0303,  0.0322, -0.0369,  0.0194, -0.0133,  0.0002,\n",
      "         0.0375,  0.0096, -0.0389,  0.0152,  0.0119,  0.0388,  0.0304, -0.0096,\n",
      "        -0.0054,  0.0289,  0.0284,  0.0183, -0.0390,  0.0247, -0.0112, -0.0305,\n",
      "         0.0314, -0.0042,  0.0101, -0.0137, -0.0057,  0.0118,  0.0368,  0.0358,\n",
      "         0.0318, -0.0337,  0.0145, -0.0413,  0.0280, -0.0377, -0.0284, -0.0295,\n",
      "        -0.0307,  0.0218, -0.0020, -0.0081,  0.0305,  0.0224, -0.0288,  0.0365,\n",
      "         0.0396, -0.0112,  0.0168,  0.0356, -0.0010,  0.0193,  0.0343, -0.0173,\n",
      "         0.0004,  0.0369, -0.0307,  0.0098,  0.0241, -0.0103,  0.0094, -0.0142,\n",
      "         0.0192,  0.0207, -0.0114,  0.0249,  0.0119,  0.0387, -0.0361,  0.0276,\n",
      "        -0.0013,  0.0403,  0.0013, -0.0316, -0.0216,  0.0220,  0.0110, -0.0313,\n",
      "        -0.0354, -0.0036,  0.0191,  0.0346, -0.0291,  0.0290, -0.0075, -0.0120,\n",
      "        -0.0142, -0.0201,  0.0390, -0.0133, -0.0238,  0.0354, -0.0206, -0.0216,\n",
      "         0.0238,  0.0264, -0.0009, -0.0095,  0.0240,  0.0230,  0.0028, -0.0210,\n",
      "        -0.0302,  0.0370,  0.0060, -0.0159,  0.0230,  0.0199,  0.0123,  0.0226,\n",
      "         0.0264,  0.0328, -0.0185, -0.0015, -0.0358,  0.0025,  0.0302, -0.0239,\n",
      "        -0.0298,  0.0180, -0.0175,  0.0070,  0.0354, -0.0223, -0.0291,  0.0042,\n",
      "         0.0209, -0.0361, -0.0236,  0.0075, -0.0077,  0.0330,  0.0204, -0.0139,\n",
      "         0.0132,  0.0094,  0.0369,  0.0318,  0.0119,  0.0003,  0.0362, -0.0072],\n",
      "       requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([256])\n",
      "tensor([ 0.0172, -0.0398,  0.0409, -0.0300,  0.0114,  0.0064,  0.0217, -0.0028,\n",
      "        -0.0082,  0.0162, -0.0158, -0.0037,  0.0349,  0.0330, -0.0374,  0.0361,\n",
      "        -0.0042,  0.0387,  0.0364,  0.0144,  0.0109,  0.0328,  0.0257,  0.0148,\n",
      "        -0.0409, -0.0300,  0.0314, -0.0344, -0.0234, -0.0082, -0.0217, -0.0282,\n",
      "        -0.0097,  0.0057, -0.0030,  0.0362,  0.0296,  0.0246,  0.0214,  0.0107,\n",
      "        -0.0220,  0.0230,  0.0070, -0.0410, -0.0207,  0.0072, -0.0291, -0.0362,\n",
      "         0.0413, -0.0185,  0.0393,  0.0341, -0.0365,  0.0268,  0.0214,  0.0096,\n",
      "        -0.0282,  0.0322,  0.0100, -0.0213, -0.0331, -0.0321, -0.0031,  0.0187,\n",
      "         0.0171,  0.0347,  0.0105, -0.0402, -0.0220, -0.0187, -0.0235,  0.0031,\n",
      "         0.0018,  0.0156, -0.0049, -0.0075,  0.0346, -0.0164, -0.0055,  0.0134,\n",
      "         0.0245,  0.0183,  0.0154,  0.0083, -0.0288, -0.0229,  0.0271, -0.0224,\n",
      "        -0.0272, -0.0281, -0.0160, -0.0334, -0.0199,  0.0348,  0.0253, -0.0298,\n",
      "         0.0283,  0.0362,  0.0113,  0.0304,  0.0324,  0.0177, -0.0325,  0.0147,\n",
      "        -0.0333,  0.0206,  0.0416,  0.0175,  0.0027, -0.0366,  0.0023,  0.0124,\n",
      "        -0.0190,  0.0090, -0.0303,  0.0322, -0.0369,  0.0194, -0.0133,  0.0002,\n",
      "         0.0375,  0.0096, -0.0389,  0.0152,  0.0119,  0.0388,  0.0304, -0.0096,\n",
      "        -0.0054,  0.0289,  0.0284,  0.0183, -0.0390,  0.0247, -0.0112, -0.0305,\n",
      "         0.0314, -0.0042,  0.0101, -0.0137, -0.0057,  0.0118,  0.0368,  0.0358,\n",
      "         0.0318, -0.0337,  0.0145, -0.0413,  0.0280, -0.0377, -0.0284, -0.0295,\n",
      "        -0.0307,  0.0218, -0.0020, -0.0081,  0.0305,  0.0224, -0.0288,  0.0365,\n",
      "         0.0396, -0.0112,  0.0168,  0.0356, -0.0010,  0.0193,  0.0343, -0.0173,\n",
      "         0.0004,  0.0369, -0.0307,  0.0098,  0.0241, -0.0103,  0.0094, -0.0142,\n",
      "         0.0192,  0.0207, -0.0114,  0.0249,  0.0119,  0.0387, -0.0361,  0.0276,\n",
      "        -0.0013,  0.0403,  0.0013, -0.0316, -0.0216,  0.0220,  0.0110, -0.0313,\n",
      "        -0.0354, -0.0036,  0.0191,  0.0346, -0.0291,  0.0290, -0.0075, -0.0120,\n",
      "        -0.0142, -0.0201,  0.0390, -0.0133, -0.0238,  0.0354, -0.0206, -0.0216,\n",
      "         0.0238,  0.0264, -0.0009, -0.0095,  0.0240,  0.0230,  0.0028, -0.0210,\n",
      "        -0.0302,  0.0370,  0.0060, -0.0159,  0.0230,  0.0199,  0.0123,  0.0226,\n",
      "         0.0264,  0.0328, -0.0185, -0.0015, -0.0358,  0.0025,  0.0302, -0.0239,\n",
      "        -0.0298,  0.0180, -0.0175,  0.0070,  0.0354, -0.0223, -0.0291,  0.0042,\n",
      "         0.0209, -0.0361, -0.0236,  0.0075, -0.0077,  0.0330,  0.0204, -0.0139,\n",
      "         0.0132,  0.0094,  0.0369,  0.0318,  0.0119,  0.0003,  0.0362, -0.0072])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([[ 0.0293,  0.0602,  0.0369,  ...,  0.0446,  0.0052,  0.0296],\n",
      "        [-0.0299,  0.0331,  0.0264,  ...,  0.0067,  0.0503,  0.0008],\n",
      "        [-0.0145,  0.0157,  0.0548,  ..., -0.0325,  0.0385,  0.0332],\n",
      "        ...,\n",
      "        [ 0.0097,  0.0621,  0.0150,  ..., -0.0317,  0.0316, -0.0410],\n",
      "        [ 0.0301, -0.0074, -0.0320,  ...,  0.0245, -0.0460,  0.0431],\n",
      "        [-0.0282,  0.0102,  0.0433,  ..., -0.0099, -0.0247, -0.0536]],\n",
      "       requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([10, 256])\n",
      "tensor([[ 0.0293,  0.0602,  0.0369,  ...,  0.0446,  0.0052,  0.0296],\n",
      "        [-0.0299,  0.0331,  0.0264,  ...,  0.0067,  0.0503,  0.0008],\n",
      "        [-0.0145,  0.0157,  0.0548,  ..., -0.0325,  0.0385,  0.0332],\n",
      "        ...,\n",
      "        [ 0.0097,  0.0621,  0.0150,  ..., -0.0317,  0.0316, -0.0410],\n",
      "        [ 0.0301, -0.0074, -0.0320,  ...,  0.0245, -0.0460,  0.0431],\n",
      "        [-0.0282,  0.0102,  0.0433,  ..., -0.0099, -0.0247, -0.0536]])\n",
      "****************************************************************************************************\n",
      " Parameters: Parameter containing:\n",
      "tensor([ 0.0156,  0.0285,  0.0260, -0.0085, -0.0308,  0.0536, -0.0277,  0.0538,\n",
      "         0.0542, -0.0313], requires_grad=True)  Type: <class 'torch.nn.parameter.Parameter'>  Shape: torch.Size([10])\n",
      "tensor([ 0.0156,  0.0285,  0.0260, -0.0085, -0.0308,  0.0536, -0.0277,  0.0538,\n",
      "         0.0542, -0.0313])\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for param in net.named_parameters():\n",
    "#     print(param)\n",
    "    name, parameters = param\n",
    "#     print(\"Name:\", name, \" Parameters:\", parameters)\n",
    "    print(\" Parameters:\", parameters, \" Type:\", type(parameters), \" Shape:\", parameters.shape)\n",
    "    print(parameters.data)\n",
    "    print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[[[ 1.4350, -0.0418,  0.0662, -1.0033, -0.9563,  0.8041,  0.0131,\n",
      "           -1.2973],\n",
      "          [-0.2135,  0.8128, -0.7179,  0.7968, -1.9276,  0.7482, -0.9018,\n",
      "            0.1769],\n",
      "          [-0.8309,  1.8309,  0.3510, -0.3548, -1.4007, -0.7809,  0.4636,\n",
      "            1.3764],\n",
      "          [-2.7068, -0.7709,  0.3637, -0.4615,  0.2624, -0.5807,  0.8520,\n",
      "            0.3480],\n",
      "          [-1.8321,  0.4307, -0.8719, -0.4008,  0.1217,  0.2684, -0.0599,\n",
      "            0.2308],\n",
      "          [ 0.3181,  1.5212,  0.0312,  0.9021,  1.1248,  0.2039, -1.1476,\n",
      "           -1.5148],\n",
      "          [-1.8644,  0.1639, -1.2798, -0.1055,  1.2482,  0.2642, -1.0575,\n",
      "           -0.5832],\n",
      "          [ 0.1748,  0.2098,  0.2814,  0.8081,  1.0729,  0.5243, -0.9525,\n",
      "            0.5459]]]])\n",
      "torch.Size([1, 1, 8, 8])\n",
      "torch.Size([1, 1, 6, 6])\n",
      "Conv X: tensor([[[[ 3.4187e-01, -6.5614e-01, -2.7153e-01, -3.0435e-01,  1.0122e-02,\n",
      "           -4.0183e-03],\n",
      "          [ 1.5786e-01, -1.6811e-01, -5.8853e-01,  3.3191e-01, -6.1250e-01,\n",
      "            8.9408e-02],\n",
      "          [ 9.8493e-01,  4.0346e-01, -2.7559e-02, -4.6522e-01, -7.2411e-01,\n",
      "           -5.2091e-01],\n",
      "          [-9.6146e-01, -8.7963e-01, -7.3858e-02, -5.1496e-01, -3.3879e-01,\n",
      "           -1.9302e-01],\n",
      "          [-4.9223e-01, -5.8010e-01, -6.2549e-01, -6.7349e-01, -5.3038e-01,\n",
      "            4.4930e-03],\n",
      "          [ 3.0968e-01,  3.3841e-01,  9.4512e-04, -2.1527e-01, -2.4843e-01,\n",
      "           -4.8096e-01]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(1, 1, kernel_size=3)\n",
    "x = torch.randn(1, 1, 8, 8)\n",
    "print(\"X:\",x)\n",
    "print(x.shape)\n",
    "print(conv(x).shape)\n",
    "print(\"Conv X:\", conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.3276,  0.1306,  0.0370],\n",
      "          [-0.1876, -0.1801,  0.0048],\n",
      "          [-0.2366,  0.0408, -0.1571]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2314], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(conv.weight)\n",
    "print(conv.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(NN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "CNN4(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBase(\n",
      "      (0): ConvBlock(\n",
      "        (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "        (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (1): ConvBlock(\n",
      "        (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "        (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (2): ConvBlock(\n",
      "        (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "        (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ConvBlock(\n",
      "        (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "        (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU()\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): Flatten()\n",
      "  )\n",
      "  (classifier): Linear(in_features=800, out_features=5, bias=True)\n",
      ")\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "\n",
    "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
    "    data, labels = batch\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Separate data into adaptation/evalutation sets\n",
    "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
    "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
    "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
    "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
    "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
    "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
    "\n",
    "    # Adapt the model\n",
    "    for step in range(adaptation_steps):\n",
    "        adaptation_error = loss(learner(adaptation_data), adaptation_labels)\n",
    "        learner.adapt(adaptation_error)\n",
    "\n",
    "    # Evaluate the adapted model\n",
    "    predictions = learner(evaluation_data)\n",
    "    evaluation_error = loss(predictions, evaluation_labels)\n",
    "    evaluation_accuracy = accuracy(predictions, evaluation_labels)\n",
    "    print(\"Adapted Network\")\n",
    "    return evaluation_error, evaluation_accuracy\n",
    "\n",
    "\n",
    "def perform_experiment(dataset,\n",
    "        ways=5,\n",
    "        shots=5,\n",
    "        meta_lr=0.003,\n",
    "        fast_lr=0.5,\n",
    "        meta_batch_size=32,\n",
    "        adaptation_steps=1,\n",
    "        num_iterations=60000,\n",
    "        cuda=True,\n",
    "        seed=42,\n",
    "):\n",
    "    \n",
    "    Meta_Train_Accuracy = []\n",
    "    Meta_Train_Error = []\n",
    "    Meta_Val_Accuracy = []\n",
    "    Meta_Val_Error = []\n",
    "    \n",
    "#     Iterations = []\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device('cpu')\n",
    "    if cuda and torch.cuda.device_count():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    # Create Tasksets using the benchmark interface\n",
    "    tasksets = l2l.vision.benchmarks.get_tasksets(dataset,\n",
    "                                                  train_samples=2*shots,\n",
    "                                                  train_ways=ways,\n",
    "                                                  test_samples=2*shots,\n",
    "                                                  test_ways=ways,\n",
    "                                                  root='~/data',\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Create model\n",
    "    model = l2l.vision.models.MiniImagenetCNN(ways)\n",
    "    model.to(device)\n",
    "    print(\"*\" * 100)\n",
    "    print(model)\n",
    "    print(\"*\" * 100)\n",
    "#     return\n",
    "    maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
    "    #Meta optimizer\n",
    "    opt = optim.Adam(maml.parameters(), meta_lr)\n",
    "    loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        opt.zero_grad()\n",
    "        meta_train_error = 0.0\n",
    "        meta_train_accuracy = 0.0\n",
    "        meta_valid_error = 0.0\n",
    "        meta_valid_accuracy = 0.0\n",
    "        for task in range(meta_batch_size):\n",
    "            print(\"Task:\", task)\n",
    "            # Compute meta-training loss\n",
    "            learner = maml.clone()\n",
    "            batch = tasksets.train.sample()\n",
    "#             print(\"Tasks Batch:\", batch)\n",
    "#             continue\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               shots,\n",
    "                                                               ways,\n",
    "                                                               device)\n",
    "            evaluation_error.backward()\n",
    "            meta_train_error += evaluation_error.item()\n",
    "            meta_train_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "            # Compute meta-validation loss\n",
    "            learner = maml.clone()\n",
    "            batch = tasksets.validation.sample()\n",
    "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                               learner,\n",
    "                                                               loss,\n",
    "                                                               adaptation_steps,\n",
    "                                                               shots,\n",
    "                                                               ways,\n",
    "                                                               device)\n",
    "            meta_valid_error += evaluation_error.item()\n",
    "            meta_valid_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "        # Print some metrics\n",
    "#         print('\\n')\n",
    "#         print('Iteration', iteration)\n",
    "#         print('Meta Train Error', meta_train_error / meta_batch_size)\n",
    "#         print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
    "#         print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
    "#         print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
    "        break\n",
    "        meta_train_error =  meta_train_error / meta_batch_size\n",
    "        meta_train_accuracy = meta_train_accuracy / meta_batch_size\n",
    "        meta_val_error =  meta_valid_error / meta_batch_size\n",
    "        meta_val_accuracy = meta_valid_accuracy / meta_batch_size\n",
    "        if(iteration % 4 ==0):\n",
    "            print('\\n')\n",
    "            print('Iteration', iteration)\n",
    "            print('Meta Train Error', meta_train_error)\n",
    "            print('Meta Train Accuracy', meta_train_accuracy)\n",
    "            print('Meta Valid Error', meta_val_error)\n",
    "            print('Meta Valid Accuracy', meta_val_accuracy)\n",
    "\n",
    "        Meta_Train_Accuracy.append(meta_train_accuracy)\n",
    "        Meta_Train_Error.append(meta_train_error)\n",
    "        Meta_Val_Accuracy.append(meta_val_accuracy)\n",
    "        Meta_Val_Error.append(meta_val_error)\n",
    "\n",
    "        # Average the accumulated gradients and optimize\n",
    "        for p in maml.parameters():\n",
    "            p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "        opt.step()\n",
    "\n",
    "    meta_test_error = 0.0\n",
    "    meta_test_accuracy = 0.0\n",
    "    for task in range(meta_batch_size):\n",
    "        # Compute meta-testing loss\n",
    "        learner = maml.clone()\n",
    "        batch = tasksets.test.sample()\n",
    "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
    "                                                           learner,\n",
    "                                                           loss,\n",
    "                                                           adaptation_steps,\n",
    "                                                           shots,\n",
    "                                                           ways,\n",
    "                                                           device)\n",
    "        meta_test_error += evaluation_error.item()\n",
    "        meta_test_accuracy += evaluation_accuracy.item()\n",
    "#     print('Meta Test Error', meta_test_error / meta_batch_size)\n",
    "#     print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
    "    Meta_Test_Error = meta_test_error / meta_batch_size\n",
    "    print('Meta Test Error', Meta_Test_Error)\n",
    "    Meta_Test_Accuracy = meta_test_accuracy / meta_batch_size\n",
    "    print('Meta Test Accuracy', Meta_Test_Accuracy)\n",
    "    \n",
    "    if not os.path.exists('plots'):\n",
    "        os.makedirs('plots')\n",
    "    if not os.path.exists('plots/acc'):\n",
    "        os.makedirs('plots/acc')\n",
    "    if not os.path.exists('plots/loss'):\n",
    "        os.makedirs('plots/loss')\n",
    "        \n",
    "    ###### Plot Accuracies ######\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(list(range(0, len(Meta_Train_Accuracy))), Meta_Train_Accuracy, label=\"Meta Train \")\n",
    "    ax.plot(list(range(0, len(Meta_Val_Accuracy))), Meta_Val_Accuracy, label=\"Meta Val\")\n",
    "#     ax.text((len(Meta_Val_Accuracy)/2), 0, 'Meta Test:{0}'.format(round(meta_test_accuracy, 2)), style='italic',\n",
    "#         bbox={'facecolor': 'red', 'alpha': 0.25, 'pad': 5})\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(0.05, 0.5, 'Meta Test:{0}'.format(round(Meta_Test_Accuracy, 2)), transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    plt.title('Adaption')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Meta Accuracy')\n",
    "    ax.legend()\n",
    "    plt.savefig('./plots/acc/{0}_ways_{1}_shots_{2}_Acc_I_{3}.png'.format(dataset, ways, shots, num_iterations),\n",
    "               dpi=150)\n",
    "    ###### Plot Accuracies ######\n",
    "\n",
    "    ###### Plot Errors ######\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(list(range(0, len(Meta_Train_Error))), Meta_Train_Error, label=\"Meta Train \")\n",
    "    ax.plot(list(range(0, len(Meta_Val_Error))), Meta_Val_Accuracy, label=\"Meta Val Lss\")\n",
    "#     ax.text((len(Meta_Val_Accuracy)/2),0, 'Meta Test Accuracy:{0}  Meta Test Loss:{1}'.format(round(meta_test_accuracy, 2),\n",
    "#                               round(meta_test_error, 2)), style='italic',\n",
    "#         bbox={'facecolor': 'red', 'alpha': 0.25, 'pad': 5})\n",
    "    ax.text(0.05, 0.5, 'MTestAcc:{0}  MTestLoss:{1}'.format(round(Meta_Test_Accuracy, 2),\n",
    "                                           round(Meta_Test_Error, 2)), transform=ax.transAxes, fontsize=14,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    plt.title('Adaption')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Meta Loss')\n",
    "    ax.legend()\n",
    "    plt.savefig('./plots/loss/{0}_ways_{1}_shots_{2}_Loss_I_{3}.png'.format(dataset, ways, shots, num_iterations), dpi=150)\n",
    "    ###### Plot Errors ######\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Ways = [5]\n",
    "    Shots = [1]#, 5]\n",
    "    Iterations = [1]#, 10000, 60000, 120000]\n",
    "    for ways in Ways:\n",
    "        for shots in Shots:\n",
    "            for iteration in Iterations:\n",
    "                \n",
    "                perform_experiment(dataset='mini-imagenet',\n",
    "                ways=ways,\n",
    "                shots=shots,\n",
    "                meta_lr=0.003,\n",
    "                fast_lr=0.5,\n",
    "                meta_batch_size=4,\n",
    "                adaptation_steps=1,\n",
    "                num_iterations=iteration,\n",
    "                cuda=True,\n",
    "                seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
