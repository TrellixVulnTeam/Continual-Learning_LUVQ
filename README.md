# Continual-Learning
## Github Commands
- [Commands](https://docs.github.com/en/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)

## Outlines
- Classics 
- Empirical Study 
- Surveys 
- Influentials 
- New Settings or Metrics 
- Regularization Methods 
- Distillation Methods 
- Rehearsal Methods 
- Generative Replay 
- Methods Dynamic Architectures or Routing Methods
- Hybrid Methods
- Continual Few-Shot Learning 
- Meta-Continual Learning 
- Lifelong Reinforcement Learning 
- Continual Generative Modeling 
- Applications 
- Thesis 
- Libraries 
- Workshops
- Benchmarks

</br>

## Classics 
- [Catastrophic forgetting in connectionist networks](https://www.sciencedirect.com/science/article/pii/S1364661399012942), (1999) by French, Robert M.
- [Lifelong robot learning](https://www.sciencedirect.com/science/article/pii/092188909500004Y), (1995) Sebastian ThrunaTom, M.Mitchellb.
## Empirical Study 
## Surveys 
## Influentials 
## New Settings or Metrics 
## Regularization Methods 
## Distillation Methods 
## Rehearsal Methods 
## Generative Replay 
## Methods Dynamic Architectures or Routing Methods
## Hybrid Methods
## Continual Few-Shot Learning 
## Meta-Continual Learning 
## Lifelong Reinforcement Learning 
## Continual Generative Modeling 
## Applications 
## Thesis 
## Libraries 
## Workshops
## Benchmarks
- [A Procedural World Generation Framework for Systematic Evaluation of Continual Learning](https://arxiv.org/abs/2106.02585), (2021) Hess, Timm, Martin Mundt, Iuliia Pliushch, and Visvanathan Ramesh.
- > Several families of continual learning techniques have been proposed to alleviate catastrophic interference in deep neural network training on non-stationary data. However, a comprehensive comparison and analysis of limitations remains largely open due to the inaccessibility to suitable datasets. Empirical examination not only varies immensely between individual works, it further currently relies on contrived composition of benchmarks through subdivision and concatenation of various prevalent static vision datasets. In this work, our goal is to bridge this gap by introducing a computer graphics simulation framework that repeatedly renders only upcoming urban scene fragments in an endless real-time procedural world generation process. At its core lies a modular parametric generative model with adaptable generative factors. The latter can be used to flexibly compose data streams, which significantly facilitates a detailed analysis and allows for effortless investigation of various continual learning schemes.
